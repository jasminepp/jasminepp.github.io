<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Tag: model compression - Hexo</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Hexo"><meta name="msapplication-TileImage" content="/img/avatar.jpg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Hexo"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Hexo"><meta property="og:url" content="http://example.com/"><meta property="og:site_name" content="Hexo"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://example.com/img/og_image.png"><meta property="article:author" content="John Doe"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://example.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"Hexo","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"John Doe"},"publisher":{"@type":"Organization","name":"Hexo","logo":{"@type":"ImageObject","url":{"text":"Tianhao'Site"}}},"description":""}</script><link rel="icon" href="/img/avatar.jpg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="jasmine"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="jasmine"></script><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Tianhao&#039;Site</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">model compression</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-06-29T23:00:00.000Z" title="30/06/2023, 00:00:00">2023-06-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a></span><span class="level-item">8 minutes read (About 1250 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/06/30/Quantization01/">Model compression-QuantizationI</a></h1><div class="content"><h3 id="I-What-is-Quantization"><a href="#I-What-is-Quantization" class="headerlink" title="I. What is Quantization?"></a>I. What is Quantization?</h3><p><strong>Quantization</strong> is the process of constraining an input from a <em>continuous</em> or  otherwise large set of values to a <em>discrete set</em></p>
<p><img src="/2023/06/30/Quantization01/img1.png"></p>
<h4 id="why-do-we-need-to-use-the-activation-function"><a href="#why-do-we-need-to-use-the-activation-function" class="headerlink" title="why do we need to use the activation function?"></a>why do we need to use the activation function?</h4><ol>
<li><h4 id="Today’s-AI-is-too-BIG"><a href="#Today’s-AI-is-too-BIG" class="headerlink" title="Today’s AI is too BIG!"></a>Today’s AI is too BIG!</h4><p><img src="/2023/06/30/Quantization01/img2.png"></p>
</li>
<li><h4 id="Memory-is-Expensive"><a href="#Memory-is-Expensive" class="headerlink" title="Memory is Expensive"></a>Memory is Expensive</h4><p><img src="/2023/06/30/Quantization01/img3.png"></p>
</li>
<li><h4 id="Low-Bit-Width-Operations-are-Cheap"><a href="#Low-Bit-Width-Operations-are-Cheap" class="headerlink" title="Low Bit-Width Operations are Cheap"></a>Low Bit-Width Operations are Cheap</h4><p><img src="/2023/06/30/Quantization01/img4.png"></p>
</li>
</ol>
<h3 id="II-Numeric-Data-Types"><a href="#II-Numeric-Data-Types" class="headerlink" title="II. Numeric Data Types"></a>II. Numeric Data Types</h3><ol>
<li><h3 id="Integer"><a href="#Integer" class="headerlink" title="Integer"></a>Integer</h3><p><img src="/2023/06/30/Quantization01/img5.png"></p>
</li>
<li><h4 id="Floating-Point-Number"><a href="#Floating-Point-Number" class="headerlink" title="Floating-Point Number"></a>Floating-Point Number</h4><p><img src="/2023/06/30/Quantization01/img6.png"></p>
</li>
</ol>
<h3 id="III-Quantization"><a href="#III-Quantization" class="headerlink" title="III Quantization"></a>III Quantization</h3><h4 id="3-1-K-Means-based-Weight-Quantization"><a href="#3-1-K-Means-based-Weight-Quantization" class="headerlink" title="3.1 K-Means based Weight Quantization"></a>3.1 K-Means based Weight Quantization</h4><ul>
<li><strong>Step 1 Weight sharing by scalar quantization</strong></li>
</ul>
<p>  First quantize the weights into <em>k</em> bins, then we only need to store a small index.</p>
<p>  <img src="/2023/06/30/Quantization01/img7.png"></p>
<ul>
<li><strong>Step 2 centroids fine-tuning</strong></li>
</ul>
<p>  During update, the <strong>gradients</strong> of same bin summed together, multiplied by the <strong>learning rate</strong> and subtracted from the shared centroids from last iteration</p>
<p>  <img src="/2023/06/30/Quantization01/img8.png"></p>
<h3 id="3-2-Linear-Quantization"><a href="#3-2-Linear-Quantization" class="headerlink" title="3.2 Linear Quantization"></a>3.2 Linear Quantization</h3><p><strong>Linear Quantization is an affine mapping of integers to real numbers</strong> <strong><u>r&#x3D;S(q-Z)</u></strong></p>
<p><img src="/2023/06/30/Quantization01/img9.png"></p>
<p><img src="/2023/06/30/Quantization01/img10.png"></p>
<h4 id="3-2-1-Linear-Quantized-Fully-Connected-Layer"><a href="#3-2-1-Linear-Quantized-Fully-Connected-Layer" class="headerlink" title="3.2.1 Linear Quantized Fully-Connected Layer"></a>3.2.1 Linear Quantized Fully-Connected Layer</h4><ol start="3">
<li><h5 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h5></li>
</ol>
<p>  ReLU function, also known as <strong>Rectified Linear Unit (RLU)</strong>, is a segmented linear function, which makes up for the gradient vanishing problem of the sigmoid function as well as the tanh function, and is widely used in current deep neural networks.The ReLU function is essentially a <strong>ramp function</strong>, and the formula and the function image are as follows:</p>
<p>  <img src="/2023/06/30/Quantization01/img6.png"></p>
<p>ReLU function is a popular activation function in deep learning, compared with sigmoid function and tanh function, it has the following <strong>advantages</strong>: </p>
<ul>
<li>When the input is positive, the derivative is 1, which <strong>improves the gradient vanishing problem</strong> to some extent and <strong>accelerates the convergence of gradient descent</strong>;</li>
<li><strong>It is much faster to compute</strong>. there are only linear relationships in the ReLU function, so it is faster to compute than sigmoid and tanh.</li>
<li><strong>Considered biologically plausible</strong>, e.g., unilateral inhibition, wide excitability bounds (i.e., excitability can be very high).</li>
</ul>
<p><strong>Shortcomings of the ReLU function:</strong></p>
<ul>
<li><p><strong>Dead ReLU problem</strong>. <em>When the input is negative, ReLU fails completely</em>, which is not a problem during forward propagation. Some regions are sensitive and some are not. <strong>But during back propagation, if the input is negative, the gradient will be completely zero;</strong></p>
</li>
<li><p><strong>Not zero-centred</strong>: Similar to the Sigmoid activation function, the output of the ReLU function is not zero-centred, the output of the ReLU function is zero or positive, introducing a bias offset to the neural network in the later layers can affect the efficiency of gradient descent.</p>
</li>
</ul>
<ol start="4">
<li><strong>Leaky ReLU</strong><br>To solve the problem of vanishing gradient in the ReLU activation function when x &lt; 0, we use <strong>Leaky ReLU</strong> - a function that tries to fix the dead ReLU problem. Let’s take a closer look at Leaky ReLU.</li>
</ol>
<p>The function expression and image are shown below:</p>
<p><img src="/2023/06/30/Quantization01/img7.png"></p>
<p><img src="/2023/06/30/Quantization01/img8.png"></p>
<h5 id="Why-would-using-Leaky-ReLU-work-better-than-ReLU"><a href="#Why-would-using-Leaky-ReLU-work-better-than-ReLU" class="headerlink" title="Why would using Leaky ReLU work better than ReLU?"></a>Why would using Leaky ReLU work better than ReLU?</h5><ul>
<li>Leaky ReLU adjusts for the problem of negative zero gradients by giving a negative input (0.01x) to a very small linear component of x, <strong>which gives a positive gradient of 0.1 when x &lt; 0</strong>. This function alleviates the dead ReLU problem to some extent.</li>
<li>leak helps to <strong>extend the range of the ReLU function</strong>, usually with a value of 0.01 or so;</li>
<li>The function range of Leaky ReLU is (negative infinity to positive infinity).</li>
</ul>
<p>Although Leaky ReLU has all the characteristics of ReLU activation function (such as computationally efficient, fast convergence, not saturated in the positive region), <strong>it does not completely prove that Leaky ReLU is always better than ReLU in practice</strong>.</p>
<ol start="5">
<li><strong>Softmax</strong><br>Softmax is an activation function for <strong>multi-class classification</strong> problems where class membership is required for more than two class labels. For any real vector of length K, Softmax can compress it into a real vector of length K with values in the range (0, 1) and the sum of the elements in the vector is 1.</li>
</ol>
<p>The expression of the function is as follows:</p>
<p><img src="/2023/06/30/Quantization01/img9.png"></p>
<p><img src="/2023/06/30/Quantization01/img10.jpg"></p>
<p>Softmax is different from the normal max function: the max function only outputs the maximum value, but Softmax ensures that smaller values have a smaller probability and are not discarded outright. We can think of it as a probabilistic or “soft” version of the argmax function.</p>
<p>The denominator of the Softmax function combines all the factors of the original output value, which means that the various probabilities obtained by the Softmax function are related to each other.</p>
<p><strong>Shortcomings of the Softmax activation function:</strong></p>
<ul>
<li><strong>It is not differentiable at zero</strong>;</li>
<li><strong>Negative inputs have a gradient of zero</strong>, which means that for activations in that region, the weights are not updated during backpropagation, thus creating dead neurons that never activate</li>
</ul>
<p>5.1  Layer and Block</p>
<p>Block</p>
<p> 1.它的任何子类都必须定义一个将其输入转换为输出的前向传播函数， 并且必须存储任何必需的参数。 有些块不需要任何参数。 最</p>
<ol start="2">
<li>为了计算梯度，块必须具有反向传播函数。</li>
</ol>
<p><em>卷积</em>（convolution）:</p>
<p>直观上可以想象在靠近输入的底层，一些通道专门识别边缘，而一些通道专门识别纹理。</p>
<p>输出大小等于输入大小�ℎ×��减去卷积核大小�ℎ×��，即：</p>
<ol start="2">
<li><pre><code>class MLP(nn.Module):
    # 用模型参数声明层。这里，我们声明两个全连接的层
    def __init__(self):
        # 调用MLP的父类Module的构造函数来执行必要的初始化。
        # 这样，在类实例化时也可以指定其他函数参数，例如模型参数params（稍后将介绍）
        super().__init__()
        self.hidden = nn.Linear(20, 256)  # 隐藏层
        self.out = nn.Linear(256, 10)  # 输出层

    # 定义模型的前向传播，即如何根据输入X返回所需的模型输出
    def forward(self, X):
        # 注意，这里我们使用ReLU的函数版本，其在nn.functional模块中定义。
        return self.out(F.relu(self.hidden(X)))
        
        
        
        
 # 构造一个二维卷积层，它具有1个输出通道和形状为（1，2）的卷积核
conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False)

# 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度），
# 其中批量大小和通道数都为1
X = X.reshape((1, 1, 6, 8))
Y = Y.reshape((1, 1, 6, 7))
lr = 3e-2  # 学习率

for i in range(10):
    Y_hat = conv2d(X)
    l = (Y_hat - Y) ** 2
    conv2d.zero_grad()
    l.sum().backward()
    # 迭代卷积核
    conv2d.weight.data[:] -= lr * conv2d.weight.grad
    if (i + 1) % 2 == 0:
        print(f&#39;epoch &#123;i+1&#125;, loss &#123;l.sum():.3f&#125;&#39;)
        
        
        
        
</code></pre>
</li>
</ol>
<p>Common Activation function</p>
<p>1.Gumberl softmax</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/633431594">通俗易懂地理解Gumbel Softmax - 知乎 (zhihu.com)</a></p>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">32</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Machine-learning/"><span class="level-start"><span class="level-item">Machine learning</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Video-Compression/"><span class="level-start"><span class="level-item">Video Compression</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-29T23:00:00.000Z">2023-07-30</time></p><p class="title"><a href="/2023/07/30/ModelCompressionPruning/">Model Compression - Pruning</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-14T23:00:00.000Z">2023-07-15</time></p><p class="title"><a href="/2023/07/15/BasicsofNeuralNetworksII/">Basics of Neural NetworksII</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-29T23:00:00.000Z">2023-06-30</time></p><p class="title"><a href="/2023/06/30/BasicsofNeuralNetworksI/">Basics of Neural NetworksI</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-29T23:00:00.000Z">2023-06-30</time></p><p class="title"><a href="/2023/06/30/Activation/">Activation Function</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-29T23:00:00.000Z">2023-06-30</time></p><p class="title"><a href="/2023/06/30/Quantization01/">Model compression-QuantizationI</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a></p></div></article></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Array/"><span class="tag">Array</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BackTracking/"><span class="tag">BackTracking</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BinarySearchTree/"><span class="tag">BinarySearchTree</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BinaryTree/"><span class="tag">BinaryTree</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C-C/"><span class="tag">C/C++</span><span class="tag">32</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Classification/"><span class="tag">Classification</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Combination/"><span class="tag">Combination</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CrossValidation/"><span class="tag">CrossValidation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DecisionTree/"><span class="tag">DecisionTree</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DeepLearning/"><span class="tag">DeepLearning</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DoublePointers/"><span class="tag">DoublePointers</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DynamicProgramming/"><span class="tag">DynamicProgramming</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FeatureExtraction/"><span class="tag">FeatureExtraction</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FeaturePreprocessing/"><span class="tag">FeaturePreprocessing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GreedyAlgorithm/"><span class="tag">GreedyAlgorithm</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Iteration/"><span class="tag">Iteration</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Java/"><span class="tag">Java</span><span class="tag">30</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KNN/"><span class="tag">KNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KnowledgeDistillation/"><span class="tag">KnowledgeDistillation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LinearRegression/"><span class="tag">LinearRegression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LinkedList/"><span class="tag">LinkedList</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linkedlist/"><span class="tag">Linkedlist</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NaiveBayes/"><span class="tag">NaiveBayes</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Optimization/"><span class="tag">Optimization</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pruning/"><span class="tag">Pruning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">20</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Regression/"><span class="tag">Regression</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Resursion/"><span class="tag">Resursion</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RidgeRegression/"><span class="tag">RidgeRegression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/String/"><span class="tag">String</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TraversalOfBinaryTree/"><span class="tag">TraversalOfBinaryTree</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VideoCompression/"><span class="tag">VideoCompression</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/deeplearning/"><span class="tag">deeplearning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/loop-invariant/"><span class="tag">loop invariant</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machinelearning/"><span class="tag">machinelearning</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/model-compression/"><span class="tag">model compression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/modelcompression/"><span class="tag">modelcompression</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/quantization/"><span class="tag">quantization</span><span class="tag">1</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.jpg" alt="Tianhao"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Tianhao</p><p class="is-size-6 is-block">a MATH and CS student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Bristol, United Kingdom</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">46</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">38</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/jasminepp/jasminepp.github.io" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/jasminepp/jasminepp.github.io"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/07/"><span class="level-start"><span class="level-item">July 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/06/"><span class="level-start"><span class="level-item">June 2023</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">May 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/04/"><span class="level-start"><span class="level-item">April 2023</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">March 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">February 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">January 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">December 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">November 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">October 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/09/"><span class="level-start"><span class="level-item">September 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">July 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">June 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">March 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/02/"><span class="level-start"><span class="level-item">February 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/01/"><span class="level-start"><span class="level-item">January 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">December 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/11/"><span class="level-start"><span class="level-item">November 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/10/"><span class="level-start"><span class="level-item">October 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Tianhao&#039;Site</a><p class="is-size-7"><span>&copy; 2023 John Doe</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="jasmine"></script><script src="jasmine"></script><script src="jasmine" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>