<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Hexo</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Hexo"><meta name="msapplication-TileImage" content="/img/avatar.jpg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Hexo"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Hexo"><meta property="og:url" content="http://example.com/"><meta property="og:site_name" content="Hexo"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://example.com/img/og_image.png"><meta property="article:author" content="John Doe"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://example.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"Hexo","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"John Doe"},"publisher":{"@type":"Organization","name":"Hexo","logo":{"@type":"ImageObject","url":{"text":"Tianhao'Site"}}},"description":""}</script><link rel="icon" href="/img/avatar.jpg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="jasmine"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="jasmine"></script><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Tianhao&#039;Site</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-04-14T23:00:00.000Z" title="15/04/2023, 00:00:00">2023-04-15</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-learning/">Machine learning</a></span><span class="level-item">8 minutes read (About 1165 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/04/15/Activation%20Function/">Machine Learning - Classification</a></h1><div class="content"><h3 id="1-4-Feature-Preprocessing"><a href="#1-4-Feature-Preprocessing" class="headerlink" title="1.4 Feature Preprocessing"></a>1.4 Feature Preprocessing</h3><p>:  Understand numerical data, categorical data characteristics Apply <strong>MinMaxScaler</strong> and <strong>StandardScaler</strong> to implement <strong>Normalisation</strong> of feature data</p>
<p>Feature preprocessing:  the process of <strong>converting feature data into feature data</strong> more suitable for the algorithmic model by means of some transformation functions.</p>
<p><img src="/2023/04/15/Activation%20Function/img1.png"></p>
<h4 id="Why-do-we-need-to-normalise-x2F-standardise"><a href="#Why-do-we-need-to-normalise-x2F-standardise" class="headerlink" title="Why do we need to normalise&#x2F;standardise?"></a>Why do we need to normalise&#x2F;standardise?</h4><p>Large differences in the units or sizes of features, or a feature whose variance is orders of magnitude larger than other features, can easily <strong>influence (dominate) the target result</strong>, preventing some algorithms from learning other features.</p>
<h4 id="1-41-Normalisation-Maps-the-data-by-transforming-the-original-data-between-default-0-1"><a href="#1-41-Normalisation-Maps-the-data-by-transforming-the-original-data-between-default-0-1" class="headerlink" title="1.41 Normalisation: Maps the data by transforming the original data between (default [0,1])"></a>1.41 Normalisation: Maps the data by transforming the original data between (default [0,1])</h4><p><img src="/2023/04/15/Activation%20Function/img2.png"></p>
<p><strong>sklearn.preprocessing.MinMaxScaler (feature_range&#x3D;(0,1)…)</strong></p>
<ul>
<li><p><strong>MinMaxScalar.fit_transform(X)</strong></p>
<p>​      X: numpy array format data[n_samples,n_features]</p>
</li>
<li><p><strong>return value</strong>: transformed array of the same shape</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">minmax_demo</span>():</span><br><span class="line">    data = pd.read_csv(<span class="string">&quot;dating.txt&quot;</span>)</span><br><span class="line">    data = data.iloc[:,:<span class="number">3</span>]  <span class="comment">#只取数据前三列</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;data=\n&quot;</span>,data)</span><br><span class="line">    transfer = MinMaxScaler() <span class="comment">#默认0-1</span></span><br><span class="line">    data_new = transfer.fit_transform(data)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;data_new=\n&quot;</span>,data_new)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    minmax_demo()</span><br></pre></td></tr></table></figure>



<p><img src="/2023/04/15/Activation%20Function/img3.png"></p>
<p>Note that the maximum and minimum values are changing, in addition, the maximum and minimum values are very <strong>susceptible</strong> to anomalies so this method is <strong>less robust</strong> and only suitable for traditional accurate small data scenarios</p>
<h4 id="1-4-2-Standardisation-Transform-the-data-to-a-mean-of-0-and-standard-deviation-of-1-by-transforming-the-original-data"><a href="#1-4-2-Standardisation-Transform-the-data-to-a-mean-of-0-and-standard-deviation-of-1-by-transforming-the-original-data" class="headerlink" title="1.4.2 Standardisation:Transform the data to a mean of 0 and standard deviation of 1 by transforming the original data."></a>1.4.2 Standardisation:Transform the data to a mean of 0 and standard deviation of 1 by transforming the original data.</h4><p>For <strong>normalisation</strong>: If outliers occur that affects the maximum and minimum values, then the result will obviously change<br>For standarlisation:If outliers occur, due to the fact that there is a With a fixed amount of data, a small number of anomalies <strong>do not have a significant effect on the mean</strong>, and thus the variance changes less.</p>
<p><img src="/2023/04/15/Activation%20Function/img4.png"></p>
<ul>
<li><strong>sklearn.preprocessing.StandardScaler()</strong><br>After processing, for each column, all data are clustered around a mean of 0 and a standard deviation of 1</li>
<li><strong>StandardScaler.fit transform(X)</strong><br>X: numpyarray format data In amples,n_features]</li>
<li><strong>return value</strong>:transformed shape of the same array</li>
</ul>
<h3 id="1-5-Feature-Reduction"><a href="#1-5-Feature-Reduction" class="headerlink" title="1.5 Feature Reduction"></a>1.5 Feature Reduction</h3><h4 id="1-5-1-Dimensionality-reduction"><a href="#1-5-1-Dimensionality-reduction" class="headerlink" title="1.5.1 Dimensionality reduction"></a>1.5.1 Dimensionality reduction</h4><p><strong>Dimensionality reduction</strong> is the process of reducing the number of random variables (features) to obtain a set of “<strong>uncorrelated</strong>“ principal variables, subject to certain constraints.</p>
<ul>
<li><strong>Reduce the number of random variables</strong></li>
</ul>
<p><img src="/2023/04/15/Activation%20Function/img5.png"></p>
<ul>
<li><strong>Correlated Feature</strong></li>
</ul>
<p>eg: Correlation between relative humidity and rainfall</p>
<p><u><em>It is because we are using features for learning when we are doing training. If there is a problem with the features themselves or if there is a strong correlation between the features, it will have a greater impact on the algorithm’s ability to learn the predictions</em></u></p>
<h4 id="1-5-2-Two-approaches-to-dimensionality-reduction"><a href="#1-5-2-Two-approaches-to-dimensionality-reduction" class="headerlink" title="1.5.2  Two approaches to dimensionality reduction"></a>1.5.2  Two approaches to dimensionality reduction</h4><ul>
<li><strong>Feature selection</strong></li>
<li><strong>Principal Component Analysis</strong> (can be understood as a form of feature extraction)</li>
</ul>
<h4 id="1-5-3-What-is-feature-selection"><a href="#1-5-3-What-is-feature-selection" class="headerlink" title="1.5.3 What is feature selection"></a>1.5.3 What is feature selection</h4><ol>
<li><strong>Definition</strong>: Data containing redundant or correlated variables (or features, attributes, metrics, etc.) designed to <strong>identify the main features</strong> from the original ones.</li>
<li><strong>Method:</strong></li>
</ol>
<ul>
<li><p><strong>Filter</strong>:  focuses on exploring the characteristics of the feature itself, the association between the feature and the feature and the target value.</p>
<ul>
<li><strong>Variance Selection</strong>: low variance feature filtering. Variance selection method: low variance feature filtering.</li>
<li><strong>Correlation Coefficient</strong></li>
</ul>
</li>
<li><p><strong>Embedded</strong>: algorithm automatically selects features (correlation between features and target value).</p>
<ul>
<li><p><strong>Decision Tree</strong>:Information Entropy, Information Gain9</p>
</li>
<li><p><strong>Regularisation</strong>:L1, L2</p>
</li>
<li><p><strong>Deep learning</strong>: convolution, etc.</p>
</li>
</ul>
</li>
</ul>
<p><strong>3. Filter</strong></p>
<p><strong>3.1</strong> <strong>Low variance feature filtering</strong><br>Remove some features with <strong>low variance</strong>, the significance of variance was covered earlier. Combined with the size of the variance to consider the perspective of this approach:</p>
<ul>
<li><strong>feature variance is small</strong>: the value of most samples of a feature is relatively similar </li>
<li><strong>feature variance is large</strong>: the value of many samples of a feature are different</li>
</ul>
<p><strong>3.1.1</strong><br><strong>sklearn.feature_selection.VarianceThreshold(threshold &#x3D; 0.0)</strong></p>
<ul>
<li>Remove all low variance features</li>
<li><strong>Variance.fit_transform(X)</strong><ul>
<li>X:numpy array format data [n_samplesn_features]</li>
<li>Return value:Features with training set variance below threshold are removed. The default value is to keep all non-zero variance features, i.e., remove all features with the same value in all samples.<br>4.1.2 Data computation<br>We perform a filter between the indicator features of certain stocks, the data is in the file “factor_regression_data&#x2F;factor_returns.csv” excluding the indexdate’return columns (these types do not match and are not required indicators).<br>These are the characteristics in total</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">variance_demo</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Low variance feature filtering</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1、load data</span></span><br><span class="line"></span><br><span class="line">​    data = pd.read_csv(<span class="string">&quot;factor_returns.csv&quot;</span>)</span><br><span class="line">​    data = data.iloc[:, <span class="number">1</span>:-<span class="number">2</span>]</span><br><span class="line">​    <span class="built_in">print</span>(<span class="string">&quot;data:\n&quot;</span>, data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、initialise transer()</span></span><br><span class="line"></span><br><span class="line">transfer = VarianceThreshold(threshold=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、use fit_transform</span></span><br><span class="line"></span><br><span class="line">data_new = transfer.fit_transform(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_new:\n&quot;</span>, data_new, data_new.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">r1 = pearsonr(data[<span class="string">&quot;pe_ratio&quot;</span>], data[<span class="string">&quot;pb_ratio&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;correlation coefficients：\n&quot;</span>, r1)</span><br><span class="line">r2 = pearsonr(data[<span class="string">&#x27;revenue&#x27;</span>], data[<span class="string">&#x27;total_expense&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;the correlation between revenue and total_expense：\n&quot;</span>, r2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>

<p><strong>3.2</strong> <strong>Correlation coefficients</strong></p>
<p><img src="/2023/04/15/Activation%20Function/img6.png"></p>
<p><strong>3.21 Characteristics</strong><br>The value of correlation coefficient lies between -1 and +1 i.e. <strong>-1&lt;&#x3D;r&lt;&#x3D;1</strong>. The properties are as follows:</p>
<ul>
<li><p>When <strong>r&gt;0</strong>, it means that the two variables are positively planted off, <strong>r&lt;0</strong>, the two variables are negatively correlated </p>
</li>
<li><p>When <strong>|r|&#x3D;1</strong>, it means that the two variables are perfectly correlated, when <strong>r&#x3D;0</strong>, it means that there is no correlation between the two variables </p>
</li>
<li><p>When <strong>0&lt;|r|&lt;1</strong>, it means that there is a certain degree of correlation between the two variables. The closer r is to 1, the closer the linear relationship between the two variables; the closer r is to 0, the weaker the linear correlation between the two variables.</p>
</li>
<li><p>Generally can be divided into <strong>three levels</strong>: <strong>r &lt; 0.4</strong> for low degree of correlation; <strong>0.4&lt;|rl &lt; 0.7</strong> for significant correlation; <strong>0.7&lt;&#x3D;|r| &lt; 1</strong> for high degree of linear correlation</p>
<figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from scipy.stats import pearsonr</span><br><span class="line">x <span class="symbol">:</span>(<span class="built_in">N</span>,)array_like</span><br><span class="line">y <span class="symbol">:</span>(<span class="built_in">N</span>,) array_like Retur<span class="symbol">ns:</span> (<span class="built_in">Pearson</span>&#x27;s correlation coefficient, p-<span class="built_in">value</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/15/Activation%20Function/img7.png"></p>
</li>
</ul>
<h3 id="1-6-PCA"><a href="#1-6-PCA" class="headerlink" title="1.6 PCA"></a>1.6 PCA</h3><h4 id="1-6-1-What-is-Principal-Component-Analysis-PCA"><a href="#1-6-1-What-is-Principal-Component-Analysis-PCA" class="headerlink" title="1.6.1 What is Principal Component Analysis (PCA)?"></a>1.6.1 What is Principal Component Analysis (PCA)?</h4><p><strong>Definition</strong>:The process of transforming high-dimensional data into low-dimensional data, in which the original data may be discarded and new variables may be created.<br><strong>Role</strong>: is the dimensionality of the data compression, as far as possible to reduce the dimensionality of the original data (complexity), the loss of a small amount of information.<br><strong>Application</strong>: regression analysis or cluster analysis.</p>
<p>​                        Given:</p>
<img src="/2023/04/15/Activation%20Function/img8.png" style="zoom:67%;">

<p><strong>Now place the data in a two-dimensional spatial Cartesian coordinate system</strong></p>
<img src="/2023/04/15/Activation%20Function/img9.png" style="zoom:67%;">

<p><strong>Now let’s figure out how to reduce the two-dimensional data to one dimension (a straight line)</strong></p>
<img src="/2023/04/15/Activation%20Function/img10.png" style="zoom:67%;">

<p> <strong>We can see that although it is reduced to one dimension, there is a loss of data from the original five points to three, and so:</strong></p>
<img src="/2023/04/15/Activation%20Function/img11.png" style="zoom:67%;">

<p><strong>sklearn.decomposition.PCA(n_components&#x3D;None</strong></p>
<ul>
<li><strong>Decompose data into lower dimensional spaces</strong></li>
<li><strong>n_components</strong></li>
</ul>
<p>​       Fractional: Indicates what percent of the information is retained</p>
<p>​     Integer: Reduces to how many features. </p>
<ul>
<li>**Pca.fit_transform(X)**X:numpy array format data [n_samples,n_features]</li>
<li><strong>Return value</strong>: array of the specified dimension after transformation</li>
</ul>
<p><strong>For example:</strong></p>
<img src="/2023/04/15/Activation%20Function/img12.png" style="zoom:67%;">

<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.decomposition  import PCA</span><br><span class="line"></span><br><span class="line">def pca_demo():</span><br><span class="line">    data = <span class="string">[[2,8,4,5],[6,3,0,8],[5,4,9,1]]</span></span><br><span class="line">    transfer = PCA(n_components=<span class="number">2</span>) #reduce to <span class="number">2</span> features</span><br><span class="line">    data_new = transfer.fit_transform(data)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;data_new:\n&quot;</span>,data_new)</span><br><span class="line">    <span class="keyword">return</span> None</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    pca_demo()</span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/15/Activation%20Function/img13.png"></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-04-14T23:00:00.000Z" title="15/04/2023, 00:00:00">2023-04-15</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a></span><span class="level-item">10 minutes read (About 1468 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/04/15/KD01/">Knowledge DistillationI</a></h1><div class="content"><h3 id="1-Background"><a href="#1-Background" class="headerlink" title="1 Background"></a>1 Background</h3><p>Although in general we don’t try to distinguish between the models used for training and deployment, there is a certain <strong>inconsistency</strong> between training and deployment:</p>
<p>During <strong>training</strong>, we need to use complex models with large computational resources in order to extract information from very large, highly redundant datasets. In experiments, the models that work best tend to be very large, or even obtained by integrating multiple models. Whereas large models are not easy to deploy into services, common limitations are as follows.</p>
<ul>
<li><strong>Slow inference speed</strong></li>
<li><strong>High deployment resource requirements (memory, graphics memory, etc.)</strong></li>
</ul>
<p>During <strong>deployment</strong>, we have strict limits on latency as well as computational resources.<br>Therefore, model compression (reducing the number of model parameters while maintaining performance) becomes an important issue. Model distillation is one of the methods of model compression.</p>
<h3 id="2-Rationale-for-knowledge-distillation"><a href="#2-Rationale-for-knowledge-distillation" class="headerlink" title="2 Rationale for knowledge distillation"></a>2 Rationale for knowledge distillation</h3><h4 id="2-1-Teacher-Model-and-Student-Model"><a href="#2-1-Teacher-Model-and-Student-Model" class="headerlink" title="2.1 Teacher Model and Student Model"></a>2.1 Teacher Model and Student Model</h4><p>Knowledge distillation uses the Teacher-Student model, in which the teacher is the output of “knowledge” and the student is the recipient of “knowledge”. The process of knowledge distillation is divided into 2 stages.</p>
<ol>
<li><strong>Original model training</strong>: Training the “<strong>Teacher model</strong>“, referred to as <strong>Net-T</strong>, which is characterised by a relatively complex model, and can also be integrated from multiple separately trained models. We do not impose any restrictions on the Teacher model in terms of model architecture, number of parameters, or whether it is integrated or not, the only requirement is that, for input X, it can output Y, where Y is mapped by <strong>softmax</strong>, and the output value corresponds to the probability value of the corresponding category.</li>
<li><strong>Streamlined model training</strong>: Train the “<strong>Student model</strong>“, abbreviated as <strong>Net-S</strong>, which is a single model with a <em><u>small number of parameters and a relatively simple model structure</u></em>. Similarly, for input X, it is possible to output Y, which is <strong>softmax</strong> mapped to the probability value of the corresponding category.</li>
</ol>
<h4 id="2-2-Key-points-in-knowledge-distillation"><a href="#2-2-Key-points-in-knowledge-distillation" class="headerlink" title="2.2 Key points in knowledge distillation"></a>2.2 Key points in knowledge distillation</h4><p>If we go back to the most basic theory of machine learning, we can clearly realise one thing (which is often overlooked after we delve into machine learning): the most fundamental aim of machine learning is to train models that <strong>generalise well</strong> to a given problem.</p>
<ul>
<li><p><strong>Generalisation</strong>: the relationship between inputs and outputs is well represented on all data for a problem, <strong>whether it’s training data, test data, or any unknown data</strong> belonging to the problem.</p>
<p>In reality, since it is impossible to collect all the data for a problem as training data, and new data are always being generated, we have to settle for the second best, and the training goal becomes modelling the relationship between inputs and outputs on the existing training dataset. Since the training dataset is a sampling of the real data distribution, <strong>the optimal solution on the training dataset tends to deviate more or less from the real optimal solution</strong></p>
</li>
</ul>
<p>And when it comes to <strong>knowledge distillation</strong>, since we already have a Net-T with strong generalisation capability, we can directly let Net-S learn the generalisation capability of Net-T when we use Net-T to distill the training Net-S.</p>
<p>A straightforward and efficient way to <strong>migrate the generalisation ability is to use the probabilities of the categories output from the softmax layer as the “soft target”.</strong></p>
<p><strong>[Comparison between the KD training process and the traditional training process]</strong></p>
<ul>
<li>Traditional training process (hard targets): <em><u>find the great likelihood of ground truth</u></em>.</li>
<li>KD’s training process (soft targets): <em><u>use class probabilities of large model as soft targets</u></em>.</li>
</ul>
<p><img src="/2023/04/15/KD01/img1.png"></p>
<h4 id="Why-is-the-KD-training-process-more-efficient"><a href="#Why-is-the-KD-training-process-more-efficient" class="headerlink" title="Why is the KD training process more efficient?"></a>Why is the KD training process more efficient?</h4><p>The output of the softmax layer, in addition to the positive examples, the <strong>negative labels also carry a lot of information</strong>, for example, some negative labels correspond to probabilities much larger than other negative labels. Whereas in the <strong>traditional</strong> training process (hard target), <strong>all negative labels are treated uniformly</strong>. In other words, the <em><strong>KD training approach makes each sample bring more information to Net-S than the traditional training approach.</strong></em></p>
<h4 id="2-3-The-softmax-function"><a href="#2-3-The-softmax-function" class="headerlink" title="2.3 The softmax function"></a>2.3 The softmax function</h4><p>Let’s review the original softmax function.</p>
<p><img src="/2023/04/15/KD01/img2.png"></p>
<p>However, if we use the output of the softmax layer as the soft target, there is another problem: <strong>when the entropy of the softmax output is relatively small, the negative labels are close to 0</strong>, and their contribution to the loss function is very small, so small that it can be ignored. Therefore, the variable “<strong>temperature</strong>“ comes in handy.</p>
<p>The following formula shows the softmax function after adding the temperature variable.</p>
<p><img src="/2023/04/15/KD01/img3.png"></p>
<p>Here T is the temperature.<br>The original softmax function is a special case of T &#x3D; 1. <em>The higher T is, the <strong>smoother</strong> the output probability distribution of softmax tends to be, the <strong>higher</strong> the entropy of its distribution is, the information carried by negative labels will be relatively amplified</em>, and the model training will <strong>pay more attention to negative labels</strong>.</p>
<h3 id="3-Specific-methods-of-knowledge-distillation"><a href="#3-Specific-methods-of-knowledge-distillation" class="headerlink" title="3 Specific methods of knowledge distillation"></a>3 Specific methods of knowledge distillation</h3><h4 id="3-1-Generic-Approach-to-Knowledge-Distillation"><a href="#3-1-Generic-Approach-to-Knowledge-Distillation" class="headerlink" title="3.1. Generic Approach to Knowledge Distillation"></a>3.1. Generic Approach to Knowledge Distillation</h4><ul>
<li>The first step is to train Net-T; </li>
<li>the second step is to distil the knowledge from Net-T to Net-S at high temperature T</li>
</ul>
<p><img src="/2023/04/15/KD01/img4.png"></p>
<p><strong>The process of high temperature distillation</strong>: The objective function of the distillation process is weighted by the <em><strong>distill loss</strong></em> (corresponding to the <strong>soft target</strong>) and the <em><strong>student loss</strong></em> (corresponding to the <strong>hard target</strong>). The diagram is shown above.</p>
<p><img src="/2023/04/15/KD01/img5.png"></p>
<p><img src="/2023/04/15/KD01/img6.png"></p>
<p>Net-T and Net-S are input into the <strong>transfer set</strong> at the same time (here we can directly reuse the training set used to train Net-T), and the softmax distribution (with high temperature) generated by Net-T is used as the <strong>soft target</strong>, and the cross entropy of the softmax output of Net-S and the soft target under the same temperature T is the <strong>first part</strong> of the Loss function:</p>
<p><img src="/2023/04/15/KD01/img7.png"></p>
<p><img src="/2023/04/15/KD01/img8.png"></p>
<p>The softmax output of Net-S for T &#x3D; 1 and the <u>cross entropy of the ground truth</u> is the <strong>second part</strong> of the Loss function</p>
<p><img src="/2023/04/15/KD01/img9.png"></p>
<p><img src="/2023/04/15/KD01/img10.png"></p>
<ul>
<li>The <strong>necessity of the second part of the Loss</strong> is actually quite easy to understand: Net-T also has a certain error rate, and the use of ground truth can effectively reduce the possibility of the error being propagated to the Net-S. For example, although a teacher is far more knowledgeable than a student, he may still make mistakes, and if the student can refer to the standard answer in addition to the teacher’s teaching, it can effectively reduce the possibility of being “led astray” by the teacher’s occasional mistakes.</li>
</ul>
<h3 id="4-Discussion-on-“temperature”"><a href="#4-Discussion-on-“temperature”" class="headerlink" title="4 Discussion on “temperature”"></a>4 Discussion on “temperature”</h3><p>We all know that “distillation” needs to be carried out at high temperatures, so what does the temperature of this “distillation” represent and how is the appropriate temperature chosen?</p>
<h4 id="4-1-Characteristics-of-temperature"><a href="#4-1-Characteristics-of-temperature" class="headerlink" title="4.1. Characteristics of temperature"></a><strong>4.1. Characteristics of temperature</strong></h4><p>Before answering this question, it is useful to discuss the <strong>characteristics of the temperature T</strong></p>
<ol>
<li><p>The original softmax function is a special case of <strong>T&#x3D;1</strong><br> When <strong>T&lt;1** the probability distribution is “steeper” than the original, and When **T&gt;1</strong> the probability distribution is “flatter” than the original. </p>
</li>
<li><p>The higher the temperature, the more evenly distributed the softmax values are (think about the extreme case:</p>
<p> (i) The softmax values are <strong>uniformly distributed</strong> when <strong>T &#x3D;   ∞</strong></p>
<p> (ii) The softmax values are equal to <em>argmax</em> when <strong>T-&gt;0</strong> i.e., the value at the maximum probability tends to 1, while the other values tend to 0)</p>
<p>Regardless of the value of the temperature T, the soft target <strong>has a tendency to ignore relatively small</strong><br> <strong>information</strong> that it carries</p>
</li>
</ol>
<h4 id="4-2-what-does-temperature-represent-and-how-to-pick-the-right-one"><a href="#4-2-what-does-temperature-represent-and-how-to-pick-the-right-one" class="headerlink" title="4.2. what does temperature represent and how to pick the right one?"></a>4.2. what does temperature represent and how to pick the right one?</h4><p><strong>What the temperature changes is how much attention is paid to the negative labels during Net-S training</strong>: when the temperature is <strong>low, less attention is paid to the negative labels</strong>, especially those that are significantly lower than the average; while when the temperature is <strong>high, the values associated with the negative labels will be relatively larger</strong>, and Net-S will pay relatively more attention to the negative labels.</p>
<p>In fact, negative labels contain certain information, especially those with values significantly higher than the mean. However, due to the training process of Net-T, it is decided that the negative label part is relatively noisy, and the lower the value of the negative label, the less reliable its information is. Therefore the temperature selection is more empirical, essentially a trade-off between the following two things.</p>
<ul>
<li><strong>Learning from negative labels that are partially informative –&gt; Temperature to be higher</strong></li>
<li><strong>Protect from noise in negative labels –&gt; keep temperature low</strong></li>
</ul>
<p>Overall, the choice of T is related to the size of the Net-S. When the number of Net-S parameters is small, a relatively low temperature is sufficient (because models with a small number of parameters can’t capture all the knowledge, so they can appropriately ignore some of the negative labels).</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-03-30T23:00:00.000Z" title="31/03/2023, 00:00:00">2023-03-31</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-learning/">Machine learning</a></span><span class="level-item">8 minutes read (About 1165 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/03/31/MachineLearning02/">Intro of Machine Learning II</a></h1><div class="content"><h3 id="1-4-Feature-Preprocessing"><a href="#1-4-Feature-Preprocessing" class="headerlink" title="1.4 Feature Preprocessing"></a>1.4 Feature Preprocessing</h3><p>:  Understand numerical data, categorical data characteristics Apply <strong>MinMaxScaler</strong> and <strong>StandardScaler</strong> to implement <strong>Normalisation</strong> of feature data</p>
<p>Feature preprocessing:  the process of <strong>converting feature data into feature data</strong> more suitable for the algorithmic model by means of some transformation functions.</p>
<p><img src="/2023/03/31/MachineLearning02/img1.png"></p>
<h4 id="Why-do-we-need-to-normalise-x2F-standardise"><a href="#Why-do-we-need-to-normalise-x2F-standardise" class="headerlink" title="Why do we need to normalise&#x2F;standardise?"></a>Why do we need to normalise&#x2F;standardise?</h4><p>Large differences in the units or sizes of features, or a feature whose variance is orders of magnitude larger than other features, can easily <strong>influence (dominate) the target result</strong>, preventing some algorithms from learning other features.</p>
<h4 id="1-41-Normalisation-Maps-the-data-by-transforming-the-original-data-between-default-0-1"><a href="#1-41-Normalisation-Maps-the-data-by-transforming-the-original-data-between-default-0-1" class="headerlink" title="1.41 Normalisation: Maps the data by transforming the original data between (default [0,1])"></a>1.41 Normalisation: Maps the data by transforming the original data between (default [0,1])</h4><p><img src="/2023/03/31/MachineLearning02/img2.png"></p>
<p><strong>sklearn.preprocessing.MinMaxScaler (feature_range&#x3D;(0,1)…)</strong></p>
<ul>
<li><p><strong>MinMaxScalar.fit_transform(X)</strong></p>
<p>​      X: numpy array format data[n_samples,n_features]</p>
</li>
<li><p><strong>return value</strong>: transformed array of the same shape</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">minmax_demo</span>():</span><br><span class="line">    data = pd.read_csv(<span class="string">&quot;dating.txt&quot;</span>)</span><br><span class="line">    data = data.iloc[:,:<span class="number">3</span>]  <span class="comment">#只取数据前三列</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;data=\n&quot;</span>,data)</span><br><span class="line">    transfer = MinMaxScaler() <span class="comment">#默认0-1</span></span><br><span class="line">    data_new = transfer.fit_transform(data)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;data_new=\n&quot;</span>,data_new)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    minmax_demo()</span><br></pre></td></tr></table></figure>



<p><img src="/2023/03/31/MachineLearning02/img3.png"></p>
<p>Note that the maximum and minimum values are changing, in addition, the maximum and minimum values are very <strong>susceptible</strong> to anomalies so this method is <strong>less robust</strong> and only suitable for traditional accurate small data scenarios</p>
<h4 id="1-4-2-Standardisation-Transform-the-data-to-a-mean-of-0-and-standard-deviation-of-1-by-transforming-the-original-data"><a href="#1-4-2-Standardisation-Transform-the-data-to-a-mean-of-0-and-standard-deviation-of-1-by-transforming-the-original-data" class="headerlink" title="1.4.2 Standardisation:Transform the data to a mean of 0 and standard deviation of 1 by transforming the original data."></a>1.4.2 Standardisation:Transform the data to a mean of 0 and standard deviation of 1 by transforming the original data.</h4><p>For <strong>normalisation</strong>: If outliers occur that affects the maximum and minimum values, then the result will obviously change<br>For standarlisation:If outliers occur, due to the fact that there is a With a fixed amount of data, a small number of anomalies <strong>do not have a significant effect on the mean</strong>, and thus the variance changes less.</p>
<p><img src="/2023/03/31/MachineLearning02/img4.png"></p>
<ul>
<li><strong>sklearn.preprocessing.StandardScaler()</strong><br>After processing, for each column, all data are clustered around a mean of 0 and a standard deviation of 1</li>
<li><strong>StandardScaler.fit transform(X)</strong><br>X: numpyarray format data In amples,n_features]</li>
<li><strong>return value</strong>:transformed shape of the same array</li>
</ul>
<h3 id="1-5-Feature-Reduction"><a href="#1-5-Feature-Reduction" class="headerlink" title="1.5 Feature Reduction"></a>1.5 Feature Reduction</h3><h4 id="1-5-1-Dimensionality-reduction"><a href="#1-5-1-Dimensionality-reduction" class="headerlink" title="1.5.1 Dimensionality reduction"></a>1.5.1 Dimensionality reduction</h4><p><strong>Dimensionality reduction</strong> is the process of reducing the number of random variables (features) to obtain a set of “<strong>uncorrelated</strong>“ principal variables, subject to certain constraints.</p>
<ul>
<li><strong>Reduce the number of random variables</strong></li>
</ul>
<p><img src="/2023/03/31/MachineLearning02/img5.png"></p>
<ul>
<li><strong>Correlated Feature</strong></li>
</ul>
<p>eg: Correlation between relative humidity and rainfall</p>
<p><u><em>It is because we are using features for learning when we are doing training. If there is a problem with the features themselves or if there is a strong correlation between the features, it will have a greater impact on the algorithm’s ability to learn the predictions</em></u></p>
<h4 id="1-5-2-Two-approaches-to-dimensionality-reduction"><a href="#1-5-2-Two-approaches-to-dimensionality-reduction" class="headerlink" title="1.5.2  Two approaches to dimensionality reduction"></a>1.5.2  Two approaches to dimensionality reduction</h4><ul>
<li><strong>Feature selection</strong></li>
<li><strong>Principal Component Analysis</strong> (can be understood as a form of feature extraction)</li>
</ul>
<h4 id="1-5-3-What-is-feature-selection"><a href="#1-5-3-What-is-feature-selection" class="headerlink" title="1.5.3 What is feature selection"></a>1.5.3 What is feature selection</h4><ol>
<li><strong>Definition</strong>: Data containing redundant or correlated variables (or features, attributes, metrics, etc.) designed to <strong>identify the main features</strong> from the original ones.</li>
<li><strong>Method:</strong></li>
</ol>
<ul>
<li><p><strong>Filter</strong>:  focuses on exploring the characteristics of the feature itself, the association between the feature and the feature and the target value.</p>
<ul>
<li><strong>Variance Selection</strong>: low variance feature filtering. Variance selection method: low variance feature filtering.</li>
<li><strong>Correlation Coefficient</strong></li>
</ul>
</li>
<li><p><strong>Embedded</strong>: algorithm automatically selects features (correlation between features and target value).</p>
<ul>
<li><p><strong>Decision Tree</strong>:Information Entropy, Information Gain9</p>
</li>
<li><p><strong>Regularisation</strong>:L1, L2</p>
</li>
<li><p><strong>Deep learning</strong>: convolution, etc.</p>
</li>
</ul>
</li>
</ul>
<p><strong>3. Filter</strong></p>
<p><strong>3.1</strong> <strong>Low variance feature filtering</strong><br>Remove some features with <strong>low variance</strong>, the significance of variance was covered earlier. Combined with the size of the variance to consider the perspective of this approach:</p>
<ul>
<li><strong>feature variance is small</strong>: the value of most samples of a feature is relatively similar </li>
<li><strong>feature variance is large</strong>: the value of many samples of a feature are different</li>
</ul>
<p><strong>3.1.1</strong><br><strong>sklearn.feature_selection.VarianceThreshold(threshold &#x3D; 0.0)</strong></p>
<ul>
<li>Remove all low variance features</li>
<li><strong>Variance.fit_transform(X)</strong><ul>
<li>X:numpy array format data [n_samplesn_features]</li>
<li>Return value:Features with training set variance below threshold are removed. The default value is to keep all non-zero variance features, i.e., remove all features with the same value in all samples.<br>4.1.2 Data computation<br>We perform a filter between the indicator features of certain stocks, the data is in the file “factor_regression_data&#x2F;factor_returns.csv” excluding the indexdate’return columns (these types do not match and are not required indicators).<br>These are the characteristics in total</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">variance_demo</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Low variance feature filtering</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1、load data</span></span><br><span class="line"></span><br><span class="line">​    data = pd.read_csv(<span class="string">&quot;factor_returns.csv&quot;</span>)</span><br><span class="line">​    data = data.iloc[:, <span class="number">1</span>:-<span class="number">2</span>]</span><br><span class="line">​    <span class="built_in">print</span>(<span class="string">&quot;data:\n&quot;</span>, data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、initialise transer()</span></span><br><span class="line"></span><br><span class="line">transfer = VarianceThreshold(threshold=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、use fit_transform</span></span><br><span class="line"></span><br><span class="line">data_new = transfer.fit_transform(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_new:\n&quot;</span>, data_new, data_new.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">r1 = pearsonr(data[<span class="string">&quot;pe_ratio&quot;</span>], data[<span class="string">&quot;pb_ratio&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;correlation coefficients：\n&quot;</span>, r1)</span><br><span class="line">r2 = pearsonr(data[<span class="string">&#x27;revenue&#x27;</span>], data[<span class="string">&#x27;total_expense&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;the correlation between revenue and total_expense：\n&quot;</span>, r2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>

<p><strong>3.2</strong> <strong>Correlation coefficients</strong></p>
<p><img src="/2023/03/31/MachineLearning02/img6.png"></p>
<p><strong>3.21 Characteristics</strong><br>The value of correlation coefficient lies between -1 and +1 i.e. <strong>-1&lt;&#x3D;r&lt;&#x3D;1</strong>. The properties are as follows:</p>
<ul>
<li><p>When <strong>r&gt;0</strong>, it means that the two variables are positively planted off, <strong>r&lt;0</strong>, the two variables are negatively correlated </p>
</li>
<li><p>When <strong>|r|&#x3D;1</strong>, it means that the two variables are perfectly correlated, when <strong>r&#x3D;0</strong>, it means that there is no correlation between the two variables </p>
</li>
<li><p>When <strong>0&lt;|r|&lt;1</strong>, it means that there is a certain degree of correlation between the two variables. The closer r is to 1, the closer the linear relationship between the two variables; the closer r is to 0, the weaker the linear correlation between the two variables.</p>
</li>
<li><p>Generally can be divided into <strong>three levels</strong>: <strong>r &lt; 0.4</strong> for low degree of correlation; <strong>0.4&lt;|rl &lt; 0.7</strong> for significant correlation; <strong>0.7&lt;&#x3D;|r| &lt; 1</strong> for high degree of linear correlation</p>
<figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from scipy.stats import pearsonr</span><br><span class="line">x <span class="symbol">:</span>(<span class="built_in">N</span>,)array_like</span><br><span class="line">y <span class="symbol">:</span>(<span class="built_in">N</span>,) array_like Retur<span class="symbol">ns:</span> (<span class="built_in">Pearson</span>&#x27;s correlation coefficient, p-<span class="built_in">value</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/2023/03/31/MachineLearning02/img7.png"></p>
</li>
</ul>
<h3 id="1-6-PCA"><a href="#1-6-PCA" class="headerlink" title="1.6 PCA"></a>1.6 PCA</h3><h4 id="1-6-1-What-is-Principal-Component-Analysis-PCA"><a href="#1-6-1-What-is-Principal-Component-Analysis-PCA" class="headerlink" title="1.6.1 What is Principal Component Analysis (PCA)?"></a>1.6.1 What is Principal Component Analysis (PCA)?</h4><p><strong>Definition</strong>:The process of transforming high-dimensional data into low-dimensional data, in which the original data may be discarded and new variables may be created.<br><strong>Role</strong>: is the dimensionality of the data compression, as far as possible to reduce the dimensionality of the original data (complexity), the loss of a small amount of information.<br><strong>Application</strong>: regression analysis or cluster analysis.</p>
<p>​                        Given:</p>
<img src="/2023/03/31/MachineLearning02/img8.png" style="zoom:67%;">

<p><strong>Now place the data in a two-dimensional spatial Cartesian coordinate system</strong></p>
<img src="/2023/03/31/MachineLearning02/img9.png" style="zoom:67%;">

<p><strong>Now let’s figure out how to reduce the two-dimensional data to one dimension (a straight line)</strong></p>
<img src="/2023/03/31/MachineLearning02/img10.png" style="zoom:67%;">

<p> <strong>We can see that although it is reduced to one dimension, there is a loss of data from the original five points to three, and so:</strong></p>
<img src="/2023/03/31/MachineLearning02/img11.png" style="zoom:67%;">

<p><strong>sklearn.decomposition.PCA(n_components&#x3D;None</strong></p>
<ul>
<li><strong>Decompose data into lower dimensional spaces</strong></li>
<li><strong>n_components</strong></li>
</ul>
<p>​       Fractional: Indicates what percent of the information is retained</p>
<p>​     Integer: Reduces to how many features. </p>
<ul>
<li>**Pca.fit_transform(X)**X:numpy array format data [n_samples,n_features]</li>
<li><strong>Return value</strong>: array of the specified dimension after transformation</li>
</ul>
<p><strong>For example:</strong></p>
<img src="/2023/03/31/MachineLearning02/img12.png" style="zoom:67%;">

<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.decomposition  import PCA</span><br><span class="line"></span><br><span class="line">def pca_demo():</span><br><span class="line">    data = <span class="string">[[2,8,4,5],[6,3,0,8],[5,4,9,1]]</span></span><br><span class="line">    transfer = PCA(n_components=<span class="number">2</span>) #reduce to <span class="number">2</span> features</span><br><span class="line">    data_new = transfer.fit_transform(data)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;data_new:\n&quot;</span>,data_new)</span><br><span class="line">    <span class="keyword">return</span> None</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    pca_demo()</span><br></pre></td></tr></table></figure>

<p><img src="/2023/03/31/MachineLearning02/img13.png"></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-03-15T00:00:00.000Z" title="15/03/2023, 00:00:00">2023-03-15</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-learning/">Machine learning</a></span><span class="level-item">10 minutes read (About 1469 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/03/15/MachineLearning01/">Intro of Machine Learning</a></h1><div class="content"><h3 id="01-Backpack"><a href="#01-Backpack" class="headerlink" title="01 Backpack"></a>01 Backpack</h3><p>There are <em><strong>n</strong></em> items and a backpack that can carry at most <em><strong>w</strong></em> weights. The weight of the ith item is <strong>weight[i]</strong> and the value obtained is <strong>value[i]</strong> . Each item can be used only once, so solve for the items in the backpack that have <em>the greatest sum of values</em>.</p>
<p><img src="/2023/03/15/MachineLearning01/img1.png"></p>
<p>There are really only <strong>two states</strong> for each item, take or don’t take, so you can use <strong>backtracking</strong> to search out all the cases, then the time complexity is <strong>o(2^n)</strong>, where <strong>n</strong> denotes the number of items.</p>
<p>So the violent solution is exponential level time complexity. It is only then that the <strong>dynamic programming</strong> solution is needed for optimisation!</p>
<p>In the following explanation, I give an example:</p>
<p>The maximum weight of the backpack is 4.</p>
<p>The items are:</p>
<p><img src="/2023/03/15/MachineLearning01/img2.png"></p>
<p>Ask what is the <em>maximum value</em> of an item that a backpack can carry?</p>
<p>The numbers that appear in the following explanations and illustrations are based on this example.</p>
<h1 id="2D-dp-01-backpacks"><a href="#2D-dp-01-backpacks" class="headerlink" title="2D dp[] 01 backpacks"></a>2D dp[] 01 backpacks</h1><h4 id="1-Determine-the-dp-and-the-meaning-of-index"><a href="#1-Determine-the-dp-and-the-meaning-of-index" class="headerlink" title="1. Determine the dp[]] and the meaning of index"></a>1. Determine the dp[]] and the meaning of index</h4><p><strong>dp[i] [j]</strong> : denotes that there are <strong>dp[i] [j]</strong> distinct paths from (0 , 0) to (i, j).</p>
<p>For the backack problem, one way to write it is to use a two-dimensional array, i.e., <strong>dp[i] [j]</strong> represents the maximum sum of the values of any of the items with index [0-i] that can be taken and put into a backpack with capacity <em><strong>j</strong></em>.</p>
<p>The following is the definition of <strong>dp[i] [j]</strong>:</p>
<p><img src="/2023/03/15/MachineLearning01/img3.png"></p>
<h4 id="2-Determine-the-recursive-formula"><a href="#2-Determine-the-recursive-formula" class="headerlink" title="2. Determine the recursive formula"></a>2. Determine the recursive formula</h4><p>Recall again the meaning of <strong>dp[i] [j]</strong>: what is the maximum sum of values that can be taken arbitrarily from the items with subscripts [0-i] and put into a backpack with capacity j.</p>
<p>Then there can be two directions to introduce <strong>dp[i] [j]</strong> that:</p>
<ul>
<li><p><strong>Do not put item i</strong>:  introduced by <strong>dp[i - 1] [j]</strong>, that is, the capacity of the backpack is <em><strong>j</strong></em>, the maximum value of not putting item <em><strong>i</strong></em> inside, at this time <strong>dp[i] [j]</strong> is <strong>dp[i - 1] [j]</strong>. (In fact, it means that when the weight of item <em><strong>i</strong></em> is greater than the weight of backpack <em><strong>j</strong></em>, item <em><strong>i</strong></em> cannot be put into the backpack, so the value in the backpack remains the same as before.)</p>
</li>
<li><p><strong>Putting item i</strong>: introduced by <strong>dp[i - 1] [j - weight[i]]</strong>, <strong>dp[i - 1] [j - weight[i]]</strong> is the <em>maximum value</em> of not putting item <em><strong>i</strong></em> when the capacity of the backpack is <em><strong>j - weight[i]</strong></em>, then <strong>dp[i - 1] [j - weight[i]] + value[i]</strong> (the value of item <em><strong>i</strong></em>) is the value of the backpack to put item <em><strong>i</strong></em> to get the the maximum value of item <em><strong>i</strong></em> in the backpack</p>
<p>So the recursive formula: <strong>dp[i] [j] &#x3D; max(dp[i - 1] [j], dp[i - 1] [j - weight[i]] + value[i])</strong></p>
</li>
</ul>
<h4 id="3-How-the-dp-is-initialised"><a href="#3-How-the-dp-is-initialised" class="headerlink" title="3. How the dp[] is initialised"></a>3. How the dp[] is initialised</h4><p>Regarding the initialisation, it must match the definition of the <strong>dp[]</strong> , otherwise it will get messier and messier when it comes to the recursive formula.</p>
<p>First from the definition of <strong>dp[i] [j]</strong>, if the backpack capacity <em><strong>j</strong></em> is 0, that is, <strong>dp[i] [0]</strong>, no matter which items are selected, the sum of the backpack value must be 0. As shown in the figure:</p>
<p><img src="/2023/03/15/MachineLearning01/img3.png"></p>
<p>Look at the other cases again:</p>
<p>The state transfer equation <strong>dp[i] [j] &#x3D; max(dp[i - 1] [j], dp[i - 1] [j - weight[i]] + value[i])</strong>; It can be seen that i is derived from <em><strong>i-1</strong></em>, and then must be initialised if <em><strong>i</strong></em> is 0.</p>
<p><strong>dp[0] [j]</strong>, i.e.: the maximum value that can be stored in a backpack of each capacity when <em><strong>i</strong></em> is 0 and the item numbered 0 is stored.</p>
<p>Then it is clear that when <strong>j &lt; weight[0]</strong>, <strong>dp[0] [j]</strong> should be 0, because the capacity of the backpack is smaller than the weight of the numbered 0 item.</p>
<p>When <strong>j &gt;&#x3D; weight[0]</strong>, <strong>dp[0] [j]</strong> should be <strong>value[0]</strong>, because the backpack capacity is enough for item number 0.</p>
<p>The code is initialised as follows:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span> ; j &lt; weight[<span class="number">0</span>]; j++) &#123;  <span class="comment">// Of course this step can be omitted if the dp[][] is pre-initialised to 0</span></span><br><span class="line">    dp[<span class="number">0</span>][j] = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// positive-order traversal</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> j = weight[<span class="number">0</span>]; j &lt;= bagweight; j++) &#123;</span><br><span class="line">    dp[<span class="number">0</span>][j] = value[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>At this point the <strong>dp[] []</strong> is initialised as shown:</p>
<p><img src="/2023/03/15/MachineLearning01/img4.png"></p>
<p>Both <strong>dp[0] [j]</strong> and <strong>dp[i] [0]</strong> are initialised, so how much should the other index be initialised?</p>
<p>In fact, from the recursive formula: <strong>dp[i] [j] &#x3D; max(dp[i - 1] [j], dp[i - 1] [j - weight[i]] + value[i])</strong>; you can see that dp[i] [j] is derived from the <u><em>upper-left value</em></u>, then the other index initialised to whatever value is OK, because they will all be overwritten.</p>
<p><strong>Initially -1, initially -2, initially 100, all are fine!</strong></p>
<p>But it’s just that it’s easier to uniformly initialise the <strong>dp[] []</strong> to 0 uniformly at the start.</p>
<p>As shown:</p>
<p><img src="/2023/03/15/MachineLearning01/img5.png"></p>
<p>Finally, the complete code is:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// initialise dp[][]</span></span><br><span class="line">vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">dp</span>(weight.<span class="built_in">size</span>(), <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;(bagweight + <span class="number">1</span>, <span class="number">0</span>));</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> j = weight[<span class="number">0</span>]; j &lt;= bagweight; j++) &#123;</span><br><span class="line">    dp[<span class="number">0</span>][j] = value[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="4-Determining-the-traversal-order"><a href="#4-Determining-the-traversal-order" class="headerlink" title="4. Determining the traversal order"></a>4. Determining the traversal order</h4><p>In the following figure, it can be seen that there are two traversal dimensions: <strong>item and pack weight</strong></p>
<p><img src="/2023/03/15/MachineLearning01/img5.png"></p>
<ul>
<li><strong>Iterate over items first, then over pack weights</strong></li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// The size of the weight array is the number of items.</span></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt; weight.<span class="built_in">size</span>(); i++) &#123; <span class="comment">// traversal item</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">0</span>; j &lt;= bagweight; j++) &#123; <span class="comment">// traversal backpack capacity</span></span><br><span class="line">        <span class="keyword">if</span> (j &lt; weight[i]) dp[i][j] = dp[i - <span class="number">1</span>][j];</span><br><span class="line">        <span class="keyword">else</span> dp[i][j] = <span class="built_in">max</span>(dp[i - <span class="number">1</span>][j], dp[i - <span class="number">1</span>][j - weight[i]] + value[i]);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>Iterate over weights first, then over item</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">0</span>; j &lt;= bagweight; j++) &#123; <span class="comment">// traversal backpack capacity</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt; weight.<span class="built_in">size</span>(); i++) &#123; <span class="comment">// traversal item</span></span><br><span class="line">        <span class="keyword">if</span> (j &lt; weight[i]) dp[i][j] = dp[i - <span class="number">1</span>][j];</span><br><span class="line">        <span class="keyword">else</span> dp[i][j] = <span class="built_in">max</span>(dp[i - <span class="number">1</span>][j], dp[i - <span class="number">1</span>][j - weight[i]] + value[i]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="5-Derivation-of-dp-by-example"><a href="#5-Derivation-of-dp-by-example" class="headerlink" title="5. Derivation of dp[] []by example"></a>5. Derivation of dp[] []by example</h4><p><img src="/2023/03/15/MachineLearning01/img6.png"></p>
<p>The end result is <strong>dp[2] [4]</strong></p>
<h3 id="amp-C"><a href="#amp-C" class="headerlink" title="&amp;C++"></a>&amp;C++</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">test_2_wei_bag_problem1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; weight = &#123;<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; value = &#123;<span class="number">15</span>, <span class="number">20</span>, <span class="number">30</span>&#125;;</span><br><span class="line">    <span class="type">int</span> bagweight = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2d-array</span></span><br><span class="line">    vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">dp</span>(weight.<span class="built_in">size</span>(), <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;(bagweight + <span class="number">1</span>, <span class="number">0</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// initialise</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> j = weight[<span class="number">0</span>]; j &lt;= bagweight; j++) &#123;</span><br><span class="line">        dp[<span class="number">0</span>][j] = value[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// size of array = number of items</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt; weight.<span class="built_in">size</span>(); i++) &#123; <span class="comment">// travesal item</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">0</span>; j &lt;= bagweight; j++) &#123; <span class="comment">// traversal backpack capacity</span></span><br><span class="line">            <span class="keyword">if</span> (j &lt; weight[i]) dp[i][j] = dp[i - <span class="number">1</span>][j];</span><br><span class="line">            <span class="keyword">else</span> dp[i][j] = <span class="built_in">max</span>(dp[i - <span class="number">1</span>][j], dp[i - <span class="number">1</span>][j - weight[i]] + value[i]);</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; dp[weight.<span class="built_in">size</span>() - <span class="number">1</span>][bagweight] &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">test_2_wei_bag_problem1</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="amp-Java"><a href="#amp-Java" class="headerlink" title="&amp;Java"></a>&amp;Java</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BagProblem</span> &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="type">static</span> <span class="type">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span>[] weight = &#123;<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>&#125;;</span><br><span class="line">        <span class="type">int</span>[] value = &#123;<span class="number">15</span>,<span class="number">20</span>,<span class="number">30</span>&#125;;</span><br><span class="line">        <span class="type">int</span> bagSize = <span class="number">4</span>;</span><br><span class="line">        <span class="built_in">testWeightBagProblem</span>(weight,value,bagSize);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="type">static</span> <span class="type">void</span> <span class="title">testWeightBagProblem</span><span class="params">(<span class="type">int</span>[] weight, <span class="type">int</span>[] value, <span class="type">int</span> bagSize)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// dp[]</span></span><br><span class="line">        <span class="type">int</span> goods = weight.length;  <span class="comment">// number of items</span></span><br><span class="line">        <span class="type">int</span>[][] dp = <span class="keyword">new</span> <span class="type">int</span>[goods][bagSize + <span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Initialise the dp array</span></span><br><span class="line">        <span class="comment">// After the array is created, the default value is 0.</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = weight[<span class="number">0</span>]; j &lt;= bagSize; j++) &#123;</span><br><span class="line">            dp[<span class="number">0</span>][j] = value[<span class="number">0</span>];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Fill the dp[][]</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; weight.length; i++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; j &lt;= bagSize; j++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (j &lt; weight[i]) &#123;</span><br><span class="line">                    <span class="comment">/**</span></span><br><span class="line"><span class="comment">                     * If the current backpack is not as big as the current item i, then item i is not put down.</span></span><br><span class="line"><span class="comment">                     * Then the maximum value of the first i-1 items that can be put down is the maximum value of the current situation.</span></span><br><span class="line"><span class="comment">                     */</span></span><br><span class="line">                    dp[i][j] = dp[i<span class="number">-1</span>][j];</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">/**</span></span><br><span class="line"><span class="comment">                     * The current capacity of the backpack can hold the item i</span></span><br><span class="line"><span class="comment">                     * Then at this point there are two scenarios:</span></span><br><span class="line"><span class="comment">                     * 1, do not put item i</span></span><br><span class="line"><span class="comment">                     * 2. Put item i</span></span><br><span class="line"><span class="comment">                     * Compare these two cases, which backpack has the largest value of items.</span></span><br><span class="line"><span class="comment">                     */</span></span><br><span class="line">                    dp[i][j] = Math.<span class="built_in">max</span>(dp[i<span class="number">-1</span>][j] , dp[i<span class="number">-1</span>][j-weight[i]] + value[i]);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// print dp[][[]]</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; goods; i++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt;= bagSize; j++) &#123;</span><br><span class="line">                System.out.<span class="built_in">print</span>(dp[i][j] + <span class="string">&quot;\t&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.<span class="built_in">println</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="amp-Python"><a href="#amp-Python" class="headerlink" title="&amp;Python"></a>&amp;Python</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#no parameter</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_2_wei_bag_problem1</span>():</span><br><span class="line">    weight = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">    value = [<span class="number">15</span>, <span class="number">20</span>, <span class="number">30</span>]</span><br><span class="line">    bagweight = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2d array</span></span><br><span class="line">    dp = [[<span class="number">0</span>] * (bagweight + <span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(weight))]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialise</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(weight[<span class="number">0</span>], bagweight + <span class="number">1</span>):</span><br><span class="line">        dp[<span class="number">0</span>][j] = value[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># size of array = number of items</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(weight)):  <span class="comment"># travesal item</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(bagweight + <span class="number">1</span>):  <span class="comment"># traversal backpack capacity</span></span><br><span class="line">            <span class="keyword">if</span> j &lt; weight[i]:</span><br><span class="line">                dp[i][j] = dp[i - <span class="number">1</span>][j]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dp[i][j] = <span class="built_in">max</span>(dp[i - <span class="number">1</span>][j], dp[i - <span class="number">1</span>][j - weight[i]] + value[i])</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(dp[<span class="built_in">len</span>(weight) - <span class="number">1</span>][bagweight])</span><br><span class="line"></span><br><span class="line">test_2_wei_bag_problem1()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#with parameter</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_2_wei_bag_problem1</span>(<span class="params">weight, value, bagweight</span>):</span><br><span class="line">    <span class="comment"># 2d array</span></span><br><span class="line">    dp = [[<span class="number">0</span>] * (bagweight + <span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(weight))]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialise</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(weight[<span class="number">0</span>], bagweight + <span class="number">1</span>):</span><br><span class="line">        dp[<span class="number">0</span>][j] = value[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># size of array = number of items</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(weight)):  <span class="comment"># travesal item</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(bagweight + <span class="number">1</span>):  <span class="comment"># traversal backpack capacity</span></span><br><span class="line">            <span class="keyword">if</span> j &lt; weight[i]:</span><br><span class="line">                dp[i][j] = dp[i - <span class="number">1</span>][j]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dp[i][j] = <span class="built_in">max</span>(dp[i - <span class="number">1</span>][j], dp[i - <span class="number">1</span>][j - weight[i]] + value[i])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dp[<span class="built_in">len</span>(weight) - <span class="number">1</span>][bagweight]</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"></span><br><span class="line">    weight = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">    value = [<span class="number">15</span>, <span class="number">20</span>, <span class="number">30</span>]</span><br><span class="line">    bagweight = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    result = test_2_wei_bag_problem1(weight, value, bagweight)</span><br><span class="line">    <span class="built_in">print</span>(result)</span><br><span class="line"></span><br></pre></td></tr></table></figure></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-02-28T00:00:00.000Z" title="28/02/2023, 00:00:00">2023-02-28</time></span><span class="level-item"><a class="link-muted" href="/categories/Algorithm/">Algorithm</a></span><span class="level-item">10 minutes read (About 1469 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/02/28/01BackpackTheoryBasics/">01 Backpack</a></h1><div class="content"><h3 id="01-Backpack"><a href="#01-Backpack" class="headerlink" title="01 Backpack"></a>01 Backpack</h3><p>There are <em><strong>n</strong></em> items and a backpack that can carry at most <em><strong>w</strong></em> weights. The weight of the ith item is <strong>weight[i]</strong> and the value obtained is <strong>value[i]</strong> . Each item can be used only once, so solve for the items in the backpack that have <em>the greatest sum of values</em>.</p>
<p><img src="/2023/02/28/01BackpackTheoryBasics/img1.png"></p>
<p>There are really only <strong>two states</strong> for each item, take or don’t take, so you can use <strong>backtracking</strong> to search out all the cases, then the time complexity is <strong>o(2^n)</strong>, where <strong>n</strong> denotes the number of items.</p>
<p>So the violent solution is exponential level time complexity. It is only then that the <strong>dynamic programming</strong> solution is needed for optimisation!</p>
<p>In the following explanation, I give an example:</p>
<p>The maximum weight of the backpack is 4.</p>
<p>The items are:</p>
<p><img src="/2023/02/28/01BackpackTheoryBasics/img2.png"></p>
<p>Ask what is the <em>maximum value</em> of an item that a backpack can carry?</p>
<p>The numbers that appear in the following explanations and illustrations are based on this example.</p>
<h1 id="2D-dp-01-backpacks"><a href="#2D-dp-01-backpacks" class="headerlink" title="2D dp[] 01 backpacks"></a>2D dp[] 01 backpacks</h1><h4 id="1-Determine-the-dp-and-the-meaning-of-index"><a href="#1-Determine-the-dp-and-the-meaning-of-index" class="headerlink" title="1. Determine the dp[]] and the meaning of index"></a>1. Determine the dp[]] and the meaning of index</h4><p><strong>dp[i] [j]</strong> : denotes that there are <strong>dp[i] [j]</strong> distinct paths from (0 , 0) to (i, j).</p>
<p>For the backack problem, one way to write it is to use a two-dimensional array, i.e., <strong>dp[i] [j]</strong> represents the maximum sum of the values of any of the items with index [0-i] that can be taken and put into a backpack with capacity <em><strong>j</strong></em>.</p>
<p>The following is the definition of <strong>dp[i] [j]</strong>:</p>
<p><img src="/2023/02/28/01BackpackTheoryBasics/img3.png"></p>
<h4 id="2-Determine-the-recursive-formula"><a href="#2-Determine-the-recursive-formula" class="headerlink" title="2. Determine the recursive formula"></a>2. Determine the recursive formula</h4><p>Recall again the meaning of <strong>dp[i] [j]</strong>: what is the maximum sum of values that can be taken arbitrarily from the items with subscripts [0-i] and put into a backpack with capacity j.</p>
<p>Then there can be two directions to introduce <strong>dp[i] [j]</strong> that:</p>
<ul>
<li><p><strong>Do not put item i</strong>:  introduced by <strong>dp[i - 1] [j]</strong>, that is, the capacity of the backpack is <em><strong>j</strong></em>, the maximum value of not putting item <em><strong>i</strong></em> inside, at this time <strong>dp[i] [j]</strong> is <strong>dp[i - 1] [j]</strong>. (In fact, it means that when the weight of item <em><strong>i</strong></em> is greater than the weight of backpack <em><strong>j</strong></em>, item <em><strong>i</strong></em> cannot be put into the backpack, so the value in the backpack remains the same as before.)</p>
</li>
<li><p><strong>Putting item i</strong>: introduced by <strong>dp[i - 1] [j - weight[i]]</strong>, <strong>dp[i - 1] [j - weight[i]]</strong> is the <em>maximum value</em> of not putting item <em><strong>i</strong></em> when the capacity of the backpack is <em><strong>j - weight[i]</strong></em>, then <strong>dp[i - 1] [j - weight[i]] + value[i]</strong> (the value of item <em><strong>i</strong></em>) is the value of the backpack to put item <em><strong>i</strong></em> to get the the maximum value of item <em><strong>i</strong></em> in the backpack</p>
<p>So the recursive formula: <strong>dp[i] [j] &#x3D; max(dp[i - 1] [j], dp[i - 1] [j - weight[i]] + value[i])</strong></p>
</li>
</ul>
<h4 id="3-How-the-dp-is-initialised"><a href="#3-How-the-dp-is-initialised" class="headerlink" title="3. How the dp[] is initialised"></a>3. How the dp[] is initialised</h4><p>Regarding the initialisation, it must match the definition of the <strong>dp[]</strong> , otherwise it will get messier and messier when it comes to the recursive formula.</p>
<p>First from the definition of <strong>dp[i] [j]</strong>, if the backpack capacity <em><strong>j</strong></em> is 0, that is, <strong>dp[i] [0]</strong>, no matter which items are selected, the sum of the backpack value must be 0. As shown in the figure:</p>
<p><img src="/2023/02/28/01BackpackTheoryBasics/img3.png"></p>
<p>Look at the other cases again:</p>
<p>The state transfer equation <strong>dp[i] [j] &#x3D; max(dp[i - 1] [j], dp[i - 1] [j - weight[i]] + value[i])</strong>; It can be seen that i is derived from <em><strong>i-1</strong></em>, and then must be initialised if <em><strong>i</strong></em> is 0.</p>
<p><strong>dp[0] [j]</strong>, i.e.: the maximum value that can be stored in a backpack of each capacity when <em><strong>i</strong></em> is 0 and the item numbered 0 is stored.</p>
<p>Then it is clear that when <strong>j &lt; weight[0]</strong>, <strong>dp[0] [j]</strong> should be 0, because the capacity of the backpack is smaller than the weight of the numbered 0 item.</p>
<p>When <strong>j &gt;&#x3D; weight[0]</strong>, <strong>dp[0] [j]</strong> should be <strong>value[0]</strong>, because the backpack capacity is enough for item number 0.</p>
<p>The code is initialised as follows:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span> ; j &lt; weight[<span class="number">0</span>]; j++) &#123;  <span class="comment">// Of course this step can be omitted if the dp[][] is pre-initialised to 0</span></span><br><span class="line">    dp[<span class="number">0</span>][j] = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// positive-order traversal</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> j = weight[<span class="number">0</span>]; j &lt;= bagweight; j++) &#123;</span><br><span class="line">    dp[<span class="number">0</span>][j] = value[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>At this point the <strong>dp[] []</strong> is initialised as shown:</p>
<p><img src="/2023/02/28/01BackpackTheoryBasics/img4.png"></p>
<p>Both <strong>dp[0] [j]</strong> and <strong>dp[i] [0]</strong> are initialised, so how much should the other index be initialised?</p>
<p>In fact, from the recursive formula: <strong>dp[i] [j] &#x3D; max(dp[i - 1] [j], dp[i - 1] [j - weight[i]] + value[i])</strong>; you can see that dp[i] [j] is derived from the <u><em>upper-left value</em></u>, then the other index initialised to whatever value is OK, because they will all be overwritten.</p>
<p><strong>Initially -1, initially -2, initially 100, all are fine!</strong></p>
<p>But it’s just that it’s easier to uniformly initialise the <strong>dp[] []</strong> to 0 uniformly at the start.</p>
<p>As shown:</p>
<p><img src="/2023/02/28/01BackpackTheoryBasics/img5.png"></p>
<p>Finally, the complete code is:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// initialise dp[][]</span></span><br><span class="line">vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">dp</span>(weight.<span class="built_in">size</span>(), <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;(bagweight + <span class="number">1</span>, <span class="number">0</span>));</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> j = weight[<span class="number">0</span>]; j &lt;= bagweight; j++) &#123;</span><br><span class="line">    dp[<span class="number">0</span>][j] = value[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="4-Determining-the-traversal-order"><a href="#4-Determining-the-traversal-order" class="headerlink" title="4. Determining the traversal order"></a>4. Determining the traversal order</h4><p>In the following figure, it can be seen that there are two traversal dimensions: <strong>item and pack weight</strong></p>
<p><img src="/2023/02/28/01BackpackTheoryBasics/img5.png"></p>
<ul>
<li><strong>Iterate over items first, then over pack weights</strong></li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// The size of the weight array is the number of items.</span></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt; weight.<span class="built_in">size</span>(); i++) &#123; <span class="comment">// traversal item</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">0</span>; j &lt;= bagweight; j++) &#123; <span class="comment">// traversal backpack capacity</span></span><br><span class="line">        <span class="keyword">if</span> (j &lt; weight[i]) dp[i][j] = dp[i - <span class="number">1</span>][j];</span><br><span class="line">        <span class="keyword">else</span> dp[i][j] = <span class="built_in">max</span>(dp[i - <span class="number">1</span>][j], dp[i - <span class="number">1</span>][j - weight[i]] + value[i]);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>Iterate over weights first, then over item</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">0</span>; j &lt;= bagweight; j++) &#123; <span class="comment">// traversal backpack capacity</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt; weight.<span class="built_in">size</span>(); i++) &#123; <span class="comment">// traversal item</span></span><br><span class="line">        <span class="keyword">if</span> (j &lt; weight[i]) dp[i][j] = dp[i - <span class="number">1</span>][j];</span><br><span class="line">        <span class="keyword">else</span> dp[i][j] = <span class="built_in">max</span>(dp[i - <span class="number">1</span>][j], dp[i - <span class="number">1</span>][j - weight[i]] + value[i]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="5-Derivation-of-dp-by-example"><a href="#5-Derivation-of-dp-by-example" class="headerlink" title="5. Derivation of dp[] []by example"></a>5. Derivation of dp[] []by example</h4><p><img src="/2023/02/28/01BackpackTheoryBasics/img6.png"></p>
<p>The end result is <strong>dp[2] [4]</strong></p>
<h3 id="amp-C"><a href="#amp-C" class="headerlink" title="&amp;C++"></a>&amp;C++</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">test_2_wei_bag_problem1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; weight = &#123;<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; value = &#123;<span class="number">15</span>, <span class="number">20</span>, <span class="number">30</span>&#125;;</span><br><span class="line">    <span class="type">int</span> bagweight = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2d-array</span></span><br><span class="line">    vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">dp</span>(weight.<span class="built_in">size</span>(), <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;(bagweight + <span class="number">1</span>, <span class="number">0</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// initialise</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> j = weight[<span class="number">0</span>]; j &lt;= bagweight; j++) &#123;</span><br><span class="line">        dp[<span class="number">0</span>][j] = value[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// size of array = number of items</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt; weight.<span class="built_in">size</span>(); i++) &#123; <span class="comment">// travesal item</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">0</span>; j &lt;= bagweight; j++) &#123; <span class="comment">// traversal backpack capacity</span></span><br><span class="line">            <span class="keyword">if</span> (j &lt; weight[i]) dp[i][j] = dp[i - <span class="number">1</span>][j];</span><br><span class="line">            <span class="keyword">else</span> dp[i][j] = <span class="built_in">max</span>(dp[i - <span class="number">1</span>][j], dp[i - <span class="number">1</span>][j - weight[i]] + value[i]);</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; dp[weight.<span class="built_in">size</span>() - <span class="number">1</span>][bagweight] &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">test_2_wei_bag_problem1</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="amp-Java"><a href="#amp-Java" class="headerlink" title="&amp;Java"></a>&amp;Java</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BagProblem</span> &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="type">static</span> <span class="type">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span>[] weight = &#123;<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>&#125;;</span><br><span class="line">        <span class="type">int</span>[] value = &#123;<span class="number">15</span>,<span class="number">20</span>,<span class="number">30</span>&#125;;</span><br><span class="line">        <span class="type">int</span> bagSize = <span class="number">4</span>;</span><br><span class="line">        <span class="built_in">testWeightBagProblem</span>(weight,value,bagSize);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="type">static</span> <span class="type">void</span> <span class="title">testWeightBagProblem</span><span class="params">(<span class="type">int</span>[] weight, <span class="type">int</span>[] value, <span class="type">int</span> bagSize)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// dp[]</span></span><br><span class="line">        <span class="type">int</span> goods = weight.length;  <span class="comment">// number of items</span></span><br><span class="line">        <span class="type">int</span>[][] dp = <span class="keyword">new</span> <span class="type">int</span>[goods][bagSize + <span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Initialise the dp array</span></span><br><span class="line">        <span class="comment">// After the array is created, the default value is 0.</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = weight[<span class="number">0</span>]; j &lt;= bagSize; j++) &#123;</span><br><span class="line">            dp[<span class="number">0</span>][j] = value[<span class="number">0</span>];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Fill the dp[][]</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; weight.length; i++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; j &lt;= bagSize; j++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (j &lt; weight[i]) &#123;</span><br><span class="line">                    <span class="comment">/**</span></span><br><span class="line"><span class="comment">                     * If the current backpack is not as big as the current item i, then item i is not put down.</span></span><br><span class="line"><span class="comment">                     * Then the maximum value of the first i-1 items that can be put down is the maximum value of the current situation.</span></span><br><span class="line"><span class="comment">                     */</span></span><br><span class="line">                    dp[i][j] = dp[i<span class="number">-1</span>][j];</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">/**</span></span><br><span class="line"><span class="comment">                     * The current capacity of the backpack can hold the item i</span></span><br><span class="line"><span class="comment">                     * Then at this point there are two scenarios:</span></span><br><span class="line"><span class="comment">                     * 1, do not put item i</span></span><br><span class="line"><span class="comment">                     * 2. Put item i</span></span><br><span class="line"><span class="comment">                     * Compare these two cases, which backpack has the largest value of items.</span></span><br><span class="line"><span class="comment">                     */</span></span><br><span class="line">                    dp[i][j] = Math.<span class="built_in">max</span>(dp[i<span class="number">-1</span>][j] , dp[i<span class="number">-1</span>][j-weight[i]] + value[i]);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// print dp[][[]]</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; goods; i++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt;= bagSize; j++) &#123;</span><br><span class="line">                System.out.<span class="built_in">print</span>(dp[i][j] + <span class="string">&quot;\t&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.<span class="built_in">println</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="amp-Python"><a href="#amp-Python" class="headerlink" title="&amp;Python"></a>&amp;Python</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#no parameter</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_2_wei_bag_problem1</span>():</span><br><span class="line">    weight = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">    value = [<span class="number">15</span>, <span class="number">20</span>, <span class="number">30</span>]</span><br><span class="line">    bagweight = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2d array</span></span><br><span class="line">    dp = [[<span class="number">0</span>] * (bagweight + <span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(weight))]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialise</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(weight[<span class="number">0</span>], bagweight + <span class="number">1</span>):</span><br><span class="line">        dp[<span class="number">0</span>][j] = value[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># size of array = number of items</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(weight)):  <span class="comment"># travesal item</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(bagweight + <span class="number">1</span>):  <span class="comment"># traversal backpack capacity</span></span><br><span class="line">            <span class="keyword">if</span> j &lt; weight[i]:</span><br><span class="line">                dp[i][j] = dp[i - <span class="number">1</span>][j]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dp[i][j] = <span class="built_in">max</span>(dp[i - <span class="number">1</span>][j], dp[i - <span class="number">1</span>][j - weight[i]] + value[i])</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(dp[<span class="built_in">len</span>(weight) - <span class="number">1</span>][bagweight])</span><br><span class="line"></span><br><span class="line">test_2_wei_bag_problem1()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#with parameter</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_2_wei_bag_problem1</span>(<span class="params">weight, value, bagweight</span>):</span><br><span class="line">    <span class="comment"># 2d array</span></span><br><span class="line">    dp = [[<span class="number">0</span>] * (bagweight + <span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(weight))]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialise</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(weight[<span class="number">0</span>], bagweight + <span class="number">1</span>):</span><br><span class="line">        dp[<span class="number">0</span>][j] = value[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># size of array = number of items</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(weight)):  <span class="comment"># travesal item</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(bagweight + <span class="number">1</span>):  <span class="comment"># traversal backpack capacity</span></span><br><span class="line">            <span class="keyword">if</span> j &lt; weight[i]:</span><br><span class="line">                dp[i][j] = dp[i - <span class="number">1</span>][j]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dp[i][j] = <span class="built_in">max</span>(dp[i - <span class="number">1</span>][j], dp[i - <span class="number">1</span>][j - weight[i]] + value[i])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dp[<span class="built_in">len</span>(weight) - <span class="number">1</span>][bagweight]</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"></span><br><span class="line">    weight = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">    value = [<span class="number">15</span>, <span class="number">20</span>, <span class="number">30</span>]</span><br><span class="line">    bagweight = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    result = test_2_wei_bag_problem1(weight, value, bagweight)</span><br><span class="line">    <span class="built_in">print</span>(result)</span><br><span class="line"></span><br></pre></td></tr></table></figure></div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/2/">Previous</a></div><div class="pagination-next"><a href="/page/4/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><a class="pagination-link" href="/page/2/">2</a></li><li><a class="pagination-link is-current" href="/page/3/">3</a></li><li><a class="pagination-link" href="/page/4/">4</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/10/">10</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">32</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Machine-learning/"><span class="level-start"><span class="level-item">Machine learning</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Video-Compression/"><span class="level-start"><span class="level-item">Video Compression</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-29T23:00:00.000Z">2023-07-30</time></p><p class="title"><a href="/2023/07/30/ModelCompressionPruning/">Model Compression - Pruning</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-14T23:00:00.000Z">2023-07-15</time></p><p class="title"><a href="/2023/07/15/BasicsofNeuralNetworksII/">Basics of Neural NetworksII</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-29T23:00:00.000Z">2023-06-30</time></p><p class="title"><a href="/2023/06/30/BasicsofNeuralNetworksI/">Basics of Neural NetworksI</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-29T23:00:00.000Z">2023-06-30</time></p><p class="title"><a href="/2023/06/30/Activation/">Activation Function</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-29T23:00:00.000Z">2023-06-30</time></p><p class="title"><a href="/2023/06/30/Quantization01/">Model compression-QuantizationI</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a></p></div></article></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Array/"><span class="tag">Array</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BackTracking/"><span class="tag">BackTracking</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BinarySearchTree/"><span class="tag">BinarySearchTree</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BinaryTree/"><span class="tag">BinaryTree</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C-C/"><span class="tag">C/C++</span><span class="tag">32</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Classification/"><span class="tag">Classification</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Combination/"><span class="tag">Combination</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CrossValidation/"><span class="tag">CrossValidation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DecisionTree/"><span class="tag">DecisionTree</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DeepLearning/"><span class="tag">DeepLearning</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DoublePointers/"><span class="tag">DoublePointers</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DynamicProgramming/"><span class="tag">DynamicProgramming</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FeatureExtraction/"><span class="tag">FeatureExtraction</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FeaturePreprocessing/"><span class="tag">FeaturePreprocessing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GreedyAlgorithm/"><span class="tag">GreedyAlgorithm</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Iteration/"><span class="tag">Iteration</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Java/"><span class="tag">Java</span><span class="tag">30</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KNN/"><span class="tag">KNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KnowledgeDistillation/"><span class="tag">KnowledgeDistillation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LinearRegression/"><span class="tag">LinearRegression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LinkedList/"><span class="tag">LinkedList</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linkedlist/"><span class="tag">Linkedlist</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NaiveBayes/"><span class="tag">NaiveBayes</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Optimization/"><span class="tag">Optimization</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pruning/"><span class="tag">Pruning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">20</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Regression/"><span class="tag">Regression</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Resursion/"><span class="tag">Resursion</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RidgeRegression/"><span class="tag">RidgeRegression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/String/"><span class="tag">String</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TraversalOfBinaryTree/"><span class="tag">TraversalOfBinaryTree</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VideoCompression/"><span class="tag">VideoCompression</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/deeplearning/"><span class="tag">deeplearning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/loop-invariant/"><span class="tag">loop invariant</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machinelearning/"><span class="tag">machinelearning</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/model-compression/"><span class="tag">model compression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/modelcompression/"><span class="tag">modelcompression</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/quantization/"><span class="tag">quantization</span><span class="tag">1</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.jpg" alt="Tianhao"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Tianhao</p><p class="is-size-6 is-block">a MATH and CS student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Bristol, United Kingdom</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">46</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">38</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/jasminepp/jasminepp.github.io" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/jasminepp/jasminepp.github.io"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/07/"><span class="level-start"><span class="level-item">July 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/06/"><span class="level-start"><span class="level-item">June 2023</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">May 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/04/"><span class="level-start"><span class="level-item">April 2023</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">March 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">February 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">January 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">December 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">November 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">October 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/09/"><span class="level-start"><span class="level-item">September 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">July 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">June 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">March 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/02/"><span class="level-start"><span class="level-item">February 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/01/"><span class="level-start"><span class="level-item">January 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">December 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/11/"><span class="level-start"><span class="level-item">November 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/10/"><span class="level-start"><span class="level-item">October 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Tianhao&#039;Site</a><p class="is-size-7"><span>&copy; 2023 John Doe</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="jasmine"></script><script src="jasmine"></script><script src="jasmine" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>