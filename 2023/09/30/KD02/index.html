<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Knowledge DistillationII - JasminePP</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="JasminePP"><meta name="msapplication-TileImage" content="/img/avatar.jpg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="JasminePP"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="1 BackgroundAlthough in general we don’t try to distinguish between the models used for training and deployment, there is a certain inconsistency between training and deployment:"><meta property="og:type" content="blog"><meta property="og:title" content="Knowledge DistillationII"><meta property="og:url" content="http://example.com/2023/09/30/KD02/"><meta property="og:site_name" content="JasminePP"><meta property="og:description" content="1 BackgroundAlthough in general we don’t try to distinguish between the models used for training and deployment, there is a certain inconsistency between training and deployment:"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://example.com/2023/09/30/KD02/img1.png"><meta property="og:image" content="http://example.com/2023/09/30/KD02/img2.png"><meta property="og:image" content="http://example.com/2023/09/30/KD02/img3.png"><meta property="og:image" content="http://example.com/2023/09/30/KD02/img4.png"><meta property="og:image" content="http://example.com/2023/09/30/KD02/img5.png"><meta property="og:image" content="http://example.com/2023/09/30/KD02/img6.png"><meta property="og:image" content="http://example.com/2023/09/30/KD02/img7.png"><meta property="og:image" content="http://example.com/2023/09/30/KD02/img8.png"><meta property="og:image" content="http://example.com/2023/09/30/KD02/img9.png"><meta property="og:image" content="http://example.com/2023/09/30/KD02/img10.png"><meta property="article:published_time" content="2023-09-29T23:00:00.000Z"><meta property="article:modified_time" content="2023-09-24T14:27:30.548Z"><meta property="article:author" content="Tianhao Peng"><meta property="article:tag" content="deeplearning"><meta property="article:tag" content="KnowledgeDistillation"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://example.com/2023/09/30/KD02/img1.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com/2023/09/30/KD02/"},"headline":"Knowledge DistillationII","image":["http://example.com/2023/09/30/KD02/img1.png","http://example.com/2023/09/30/KD02/img2.png","http://example.com/2023/09/30/KD02/img3.png","http://example.com/2023/09/30/KD02/img4.png","http://example.com/2023/09/30/KD02/img5.png","http://example.com/2023/09/30/KD02/img6.png","http://example.com/2023/09/30/KD02/img7.png","http://example.com/2023/09/30/KD02/img8.png","http://example.com/2023/09/30/KD02/img9.png","http://example.com/2023/09/30/KD02/img10.png"],"datePublished":"2023-09-29T23:00:00.000Z","dateModified":"2023-09-24T14:27:30.548Z","author":{"@type":"Person","name":"Tianhao Peng"},"publisher":{"@type":"Organization","name":"JasminePP","logo":{"@type":"ImageObject","url":{"text":"Tianhao'Site"}}},"description":"1 BackgroundAlthough in general we don’t try to distinguish between the models used for training and deployment, there is a certain inconsistency between training and deployment:"}</script><link rel="canonical" href="http://example.com/2023/09/30/KD02/"><link rel="icon" href="/img/avatar.jpg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="jasmine"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="jasmine"></script><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Tianhao&#039;Site</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-09-29T23:00:00.000Z" title="30/09/2023, 00:00:00">2023-09-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a></span><span class="level-item">10 minutes read (About 1469 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Knowledge DistillationII</h1><div class="content"><h3 id="1-Background"><a href="#1-Background" class="headerlink" title="1 Background"></a>1 Background</h3><p>Although in general we don’t try to distinguish between the models used for training and deployment, there is a certain <strong>inconsistency</strong> between training and deployment:</p>
<span id="more"></span>

<p>During <strong>training</strong>, we need to use complex models with large computational resources in order to extract information from very large, highly redundant datasets. In experiments, the models that work best tend to be very large, or even obtained by integrating multiple models. Whereas large models are not easy to deploy into services, common limitations are as follows.</p>
<ul>
<li><strong>Slow inference speed</strong></li>
<li><strong>High deployment resource requirements (memory, graphics memory, etc.)</strong></li>
</ul>
<p>During <strong>deployment</strong>, we have strict limits on latency as well as computational resources.<br>Therefore, model compression (reducing the number of model parameters while maintaining performance) becomes an important issue. Model distillation is one of the methods of model compression.</p>
<h3 id="2-Rationale-for-knowledge-distillation"><a href="#2-Rationale-for-knowledge-distillation" class="headerlink" title="2 Rationale for knowledge distillation"></a>2 Rationale for knowledge distillation</h3><h4 id="2-1-Teacher-Model-and-Student-Model"><a href="#2-1-Teacher-Model-and-Student-Model" class="headerlink" title="2.1 Teacher Model and Student Model"></a>2.1 Teacher Model and Student Model</h4><p>Knowledge distillation uses the Teacher-Student model, in which the teacher is the output of “knowledge” and the student is the recipient of “knowledge”. The process of knowledge distillation is divided into 2 stages.</p>
<ol>
<li><strong>Original model training</strong>: Training the “<strong>Teacher model</strong>“, referred to as <strong>Net-T</strong>, which is characterised by a relatively complex model, and can also be integrated from multiple separately trained models. We do not impose any restrictions on the Teacher model in terms of model architecture, number of parameters, or whether it is integrated or not, the only requirement is that, for input X, it can output Y, where Y is mapped by <strong>softmax</strong>, and the output value corresponds to the probability value of the corresponding category.</li>
<li><strong>Streamlined model training</strong>: Train the “<strong>Student model</strong>“, abbreviated as <strong>Net-S</strong>, which is a single model with a <em><u>small number of parameters and a relatively simple model structure</u></em>. Similarly, for input X, it is possible to output Y, which is <strong>softmax</strong> mapped to the probability value of the corresponding category.</li>
</ol>
<h4 id="2-2-Key-points-in-knowledge-distillation"><a href="#2-2-Key-points-in-knowledge-distillation" class="headerlink" title="2.2 Key points in knowledge distillation"></a>2.2 Key points in knowledge distillation</h4><p>If we go back to the most basic theory of machine learning, we can clearly realise one thing (which is often overlooked after we delve into machine learning): the most fundamental aim of machine learning is to train models that <strong>generalise well</strong> to a given problem.</p>
<ul>
<li><p><strong>Generalisation</strong>: the relationship between inputs and outputs is well represented on all data for a problem, <strong>whether it’s training data, test data, or any unknown data</strong> belonging to the problem.</p>
<p>In reality, since it is impossible to collect all the data for a problem as training data, and new data are always being generated, we have to settle for the second best, and the training goal becomes modelling the relationship between inputs and outputs on the existing training dataset. Since the training dataset is a sampling of the real data distribution, <strong>the optimal solution on the training dataset tends to deviate more or less from the real optimal solution</strong></p>
</li>
</ul>
<p>And when it comes to <strong>knowledge distillation</strong>, since we already have a Net-T with strong generalisation capability, we can directly let Net-S learn the generalisation capability of Net-T when we use Net-T to distill the training Net-S.</p>
<p>A straightforward and efficient way to <strong>migrate the generalisation ability is to use the probabilities of the categories output from the softmax layer as the “soft target”.</strong></p>
<p><strong>[Comparison between the KD training process and the traditional training process]</strong></p>
<ul>
<li>Traditional training process (hard targets): <em><u>find the great likelihood of ground truth</u></em>.</li>
<li>KD’s training process (soft targets): <em><u>use class probabilities of large model as soft targets</u></em>.</li>
</ul>
<p><img src="/2023/09/30/KD02/img1.png"></p>
<h4 id="Why-is-the-KD-training-process-more-efficient"><a href="#Why-is-the-KD-training-process-more-efficient" class="headerlink" title="Why is the KD training process more efficient?"></a>Why is the KD training process more efficient?</h4><p>The output of the softmax layer, in addition to the positive examples, the <strong>negative labels also carry a lot of information</strong>, for example, some negative labels correspond to probabilities much larger than other negative labels. Whereas in the <strong>traditional</strong> training process (hard target), <strong>all negative labels are treated uniformly</strong>. In other words, the <em><strong>KD training approach makes each sample bring more information to Net-S than the traditional training approach.</strong></em></p>
<h4 id="2-3-The-softmax-function"><a href="#2-3-The-softmax-function" class="headerlink" title="2.3 The softmax function"></a>2.3 The softmax function</h4><p>Let’s review the original softmax function.</p>
<p><img src="/2023/09/30/KD02/img2.png"></p>
<p>However, if we use the output of the softmax layer as the soft target, there is another problem: <strong>when the entropy of the softmax output is relatively small, the negative labels are close to 0</strong>, and their contribution to the loss function is very small, so small that it can be ignored. Therefore, the variable “<strong>temperature</strong>“ comes in handy.</p>
<p>The following formula shows the softmax function after adding the temperature variable.</p>
<p><img src="/2023/09/30/KD02/img3.png"></p>
<p>Here T is the temperature.<br>The original softmax function is a special case of T &#x3D; 1. <em>The higher T is, the <strong>smoother</strong> the output probability distribution of softmax tends to be, the <strong>higher</strong> the entropy of its distribution is, the information carried by negative labels will be relatively amplified</em>, and the model training will <strong>pay more attention to negative labels</strong>.</p>
<h3 id="3-Specific-methods-of-knowledge-distillation"><a href="#3-Specific-methods-of-knowledge-distillation" class="headerlink" title="3 Specific methods of knowledge distillation"></a>3 Specific methods of knowledge distillation</h3><h4 id="3-1-Generic-Approach-to-Knowledge-Distillation"><a href="#3-1-Generic-Approach-to-Knowledge-Distillation" class="headerlink" title="3.1. Generic Approach to Knowledge Distillation"></a>3.1. Generic Approach to Knowledge Distillation</h4><ul>
<li>The first step is to train Net-T; </li>
<li>the second step is to distil the knowledge from Net-T to Net-S at high temperature T</li>
</ul>
<p><img src="/2023/09/30/KD02/img4.png"></p>
<p><strong>The process of high temperature distillation</strong>: The objective function of the distillation process is weighted by the <em><strong>distill loss</strong></em> (corresponding to the <strong>soft target</strong>) and the <em><strong>student loss</strong></em> (corresponding to the <strong>hard target</strong>). The diagram is shown above.</p>
<p><img src="/2023/09/30/KD02/img5.png"></p>
<p><img src="/2023/09/30/KD02/img6.png"></p>
<p>Net-T and Net-S are input into the <strong>transfer set</strong> at the same time (here we can directly reuse the training set used to train Net-T), and the softmax distribution (with high temperature) generated by Net-T is used as the <strong>soft target</strong>, and the cross entropy of the softmax output of Net-S and the soft target under the same temperature T is the <strong>first part</strong> of the Loss function:</p>
<p><img src="/2023/09/30/KD02/img7.png"></p>
<p><img src="/2023/09/30/KD02/img8.png"></p>
<p>The softmax output of Net-S for T &#x3D; 1 and the <u>cross entropy of the ground truth</u> is the <strong>second part</strong> of the Loss function</p>
<p><img src="/2023/09/30/KD02/img9.png"></p>
<p><img src="/2023/09/30/KD02/img10.png"></p>
<ul>
<li>The <strong>necessity of the second part of the Loss</strong> is actually quite easy to understand: Net-T also has a certain error rate, and the use of ground truth can effectively reduce the possibility of the error being propagated to the Net-S. For example, although a teacher is far more knowledgeable than a student, he may still make mistakes, and if the student can refer to the standard answer in addition to the teacher’s teaching, it can effectively reduce the possibility of being “led astray” by the teacher’s occasional mistakes.</li>
</ul>
<h3 id="4-Discussion-on-“temperature”"><a href="#4-Discussion-on-“temperature”" class="headerlink" title="4 Discussion on “temperature”"></a>4 Discussion on “temperature”</h3><p>We all know that “distillation” needs to be carried out at high temperatures, so what does the temperature of this “distillation” represent and how is the appropriate temperature chosen?</p>
<h4 id="4-1-Characteristics-of-temperature"><a href="#4-1-Characteristics-of-temperature" class="headerlink" title="4.1. Characteristics of temperature"></a><strong>4.1. Characteristics of temperature</strong></h4><p>Before answering this question, it is useful to discuss the <strong>characteristics of the temperature T</strong></p>
<ol>
<li><p>The original softmax function is a special case of <strong>T&#x3D;1</strong><br> When <strong>T&lt;1** the probability distribution is “steeper” than the original, and When **T&gt;1</strong> the probability distribution is “flatter” than the original. </p>
</li>
<li><p>The higher the temperature, the more evenly distributed the softmax values are (think about the extreme case:</p>
<p> (i) The softmax values are <strong>uniformly distributed</strong> when <strong>T &#x3D;   ∞</strong></p>
<p> (ii) The softmax values are equal to <em>argmax</em> when <strong>T-&gt;0</strong> i.e., the value at the maximum probability tends to 1, while the other values tend to 0)</p>
<p>Regardless of the value of the temperature T, the soft target <strong>has a tendency to ignore relatively small</strong><br> <strong>information</strong> that it carries</p>
</li>
</ol>
<h4 id="4-2-what-does-temperature-represent-and-how-to-pick-the-right-one"><a href="#4-2-what-does-temperature-represent-and-how-to-pick-the-right-one" class="headerlink" title="4.2. what does temperature represent and how to pick the right one?"></a>4.2. what does temperature represent and how to pick the right one?</h4><p><strong>What the temperature changes is how much attention is paid to the negative labels during Net-S training</strong>: when the temperature is <strong>low, less attention is paid to the negative labels</strong>, especially those that are significantly lower than the average; while when the temperature is <strong>high, the values associated with the negative labels will be relatively larger</strong>, and Net-S will pay relatively more attention to the negative labels.</p>
<p>In fact, negative labels contain certain information, especially those with values significantly higher than the mean. However, due to the training process of Net-T, it is decided that the negative label part is relatively noisy, and the lower the value of the negative label, the less reliable its information is. Therefore the temperature selection is more empirical, essentially a trade-off between the following two things.</p>
<ul>
<li><strong>Learning from negative labels that are partially informative –&gt; Temperature to be higher</strong></li>
<li><strong>Protect from noise in negative labels –&gt; keep temperature low</strong></li>
</ul>
<p>Overall, the choice of T is related to the size of the Net-S. When the number of Net-S parameters is small, a relatively low temperature is sufficient (because models with a small number of parameters can’t capture all the knowledge, so they can appropriately ignore some of the negative labels).</p>
</div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/deeplearning/">deeplearning</a><a class="link-muted mr-2" rel="tag" href="/tags/KnowledgeDistillation/">KnowledgeDistillation</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2023/09/15/KD01/"><span class="level-item">Knowledge DistillationI</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">32</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Machine-learning/"><span class="level-start"><span class="level-item">Machine learning</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Video-Compression/"><span class="level-start"><span class="level-item">Video Compression</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-09-29T23:00:00.000Z">2023-09-30</time></p><p class="title"><a href="/2023/09/30/KD02/">Knowledge DistillationII</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-09-14T23:00:00.000Z">2023-09-15</time></p><p class="title"><a href="/2023/09/15/KD01/">Knowledge DistillationI</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-08-29T23:00:00.000Z">2023-08-30</time></p><p class="title"><a href="/2023/08/30/ModelCompressionPruning/">Model Compression - Pruning</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-08-14T23:00:00.000Z">2023-08-15</time></p><p class="title"><a href="/2023/08/15/Activation/">Activation Function</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-29T23:00:00.000Z">2023-07-30</time></p><p class="title"><a href="/2023/07/30/BasicsofNeuralNetworksII/">Basics of Neural NetworksII</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a></p></div></article></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Array/"><span class="tag">Array</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BackTracking/"><span class="tag">BackTracking</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BinarySearchTree/"><span class="tag">BinarySearchTree</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BinaryTree/"><span class="tag">BinaryTree</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C-C/"><span class="tag">C/C++</span><span class="tag">32</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Classification/"><span class="tag">Classification</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Combination/"><span class="tag">Combination</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CrossValidation/"><span class="tag">CrossValidation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DecisionTree/"><span class="tag">DecisionTree</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DeepLearning/"><span class="tag">DeepLearning</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DoublePointers/"><span class="tag">DoublePointers</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DynamicProgramming/"><span class="tag">DynamicProgramming</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FeatureExtraction/"><span class="tag">FeatureExtraction</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FeaturePreprocessing/"><span class="tag">FeaturePreprocessing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GreedyAlgorithm/"><span class="tag">GreedyAlgorithm</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Iteration/"><span class="tag">Iteration</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Java/"><span class="tag">Java</span><span class="tag">30</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KNN/"><span class="tag">KNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KnowledgeDistillation/"><span class="tag">KnowledgeDistillation</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LinearRegression/"><span class="tag">LinearRegression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LinkedList/"><span class="tag">LinkedList</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linkedlist/"><span class="tag">Linkedlist</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NaiveBayes/"><span class="tag">NaiveBayes</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Optimization/"><span class="tag">Optimization</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pruning/"><span class="tag">Pruning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">20</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Regression/"><span class="tag">Regression</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Resursion/"><span class="tag">Resursion</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RidgeRegression/"><span class="tag">RidgeRegression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/String/"><span class="tag">String</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TraversalOfBinaryTree/"><span class="tag">TraversalOfBinaryTree</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VideoCompression/"><span class="tag">VideoCompression</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/deeplearning/"><span class="tag">deeplearning</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/loop-invariant/"><span class="tag">loop invariant</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machinelearning/"><span class="tag">machinelearning</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/model-compression/"><span class="tag">model compression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/modelcompression/"><span class="tag">modelcompression</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/quantization/"><span class="tag">quantization</span><span class="tag">1</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.jpg" alt="Tianhao"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Tianhao</p><p class="is-size-6 is-block">a MATH and CS student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Bristol, United Kingdom</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">46</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">38</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/jasminepp/jasminepp.github.io" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/jasminepp/jasminepp.github.io"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/09/"><span class="level-start"><span class="level-item">September 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/08/"><span class="level-start"><span class="level-item">August 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/07/"><span class="level-start"><span class="level-item">July 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/06/"><span class="level-start"><span class="level-item">June 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">May 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/04/"><span class="level-start"><span class="level-item">April 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">March 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">February 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">January 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">December 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">November 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">October 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/09/"><span class="level-start"><span class="level-item">September 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">July 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">June 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">March 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/02/"><span class="level-start"><span class="level-item">February 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/01/"><span class="level-start"><span class="level-item">January 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">December 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/11/"><span class="level-start"><span class="level-item">November 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/10/"><span class="level-start"><span class="level-item">October 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Tianhao&#039;Site</a><p class="is-size-7"><span>&copy; 2023 Tianhao Peng</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="jasmine"></script><script src="jasmine"></script><script src="jasmine" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="jasmine" defer></script><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>