<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Machine Learning - ClassificationII - JasminePP</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="JasminePP"><meta name="msapplication-TileImage" content="/img/avatar.jpg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="JasminePP"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="1.4 Navie Bayes1.4.1 What is a Navie Bayesian?Naive Bayes is a probabilistic machine learning algorithm based on the Bayes Theorem, used in a wide variety of classification tasks.    1.4.2 What is Con"><meta property="og:type" content="blog"><meta property="og:title" content="Machine Learning - ClassificationII"><meta property="og:url" content="http://example.com/2023/04/30/MachineLearning04/"><meta property="og:site_name" content="JasminePP"><meta property="og:description" content="1.4 Navie Bayes1.4.1 What is a Navie Bayesian?Naive Bayes is a probabilistic machine learning algorithm based on the Bayes Theorem, used in a wide variety of classification tasks.    1.4.2 What is Con"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://example.com/2023/04/30/MachineLearning04/img02.png"><meta property="og:image" content="http://example.com/2023/04/30/MachineLearning04/img01.png"><meta property="og:image" content="http://example.com/2023/04/30/MachineLearning04/img03.png"><meta property="og:image" content="http://example.com/2023/04/30/MachineLearning04/img04.png"><meta property="og:image" content="http://example.com/2023/04/30/MachineLearning04/img05.png"><meta property="og:image" content="http://example.com/2023/04/30/MachineLearning04/img06.png"><meta property="og:image" content="http://example.com/2023/04/30/MachineLearning04/img07.png"><meta property="og:image" content="http://example.com/2023/04/30/MachineLearning04/img08.png"><meta property="og:image" content="http://example.com/2023/04/30/MachineLearning04/img09.jpg"><meta property="og:image" content="http://example.com/2023/04/30/MachineLearning04/img10.png"><meta property="og:image" content="http://example.com/2023/04/30/MachineLearning04/img11.png"><meta property="og:image" content="http://example.com/2023/04/30/MachineLearning04/img12.jpg"><meta property="article:published_time" content="2023-04-29T23:00:00.000Z"><meta property="article:modified_time" content="2023-09-02T13:47:45.752Z"><meta property="article:author" content="Tianhao Peng"><meta property="article:tag" content="machinelearning"><meta property="article:tag" content="Classification"><meta property="article:tag" content="NaiveBayes"><meta property="article:tag" content="DecisionTree"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://example.com/2023/04/30/MachineLearning04/img02.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com/2023/04/30/MachineLearning04/"},"headline":"Machine Learning - ClassificationII","image":["http://example.com/2023/04/30/MachineLearning04/img02.png","http://example.com/2023/04/30/MachineLearning04/img01.png","http://example.com/2023/04/30/MachineLearning04/img03.png","http://example.com/2023/04/30/MachineLearning04/img04.png","http://example.com/2023/04/30/MachineLearning04/img05.png","http://example.com/2023/04/30/MachineLearning04/img06.png","http://example.com/2023/04/30/MachineLearning04/img07.png","http://example.com/2023/04/30/MachineLearning04/img08.png","http://example.com/2023/04/30/MachineLearning04/img09.jpg","http://example.com/2023/04/30/MachineLearning04/img10.png","http://example.com/2023/04/30/MachineLearning04/img11.png","http://example.com/2023/04/30/MachineLearning04/img12.jpg"],"datePublished":"2023-04-29T23:00:00.000Z","dateModified":"2023-09-02T13:47:45.752Z","author":{"@type":"Person","name":"Tianhao Peng"},"publisher":{"@type":"Organization","name":"JasminePP","logo":{"@type":"ImageObject","url":{"text":"Tianhao'Site"}}},"description":"1.4 Navie Bayes1.4.1 What is a Navie Bayesian?Naive Bayes is a probabilistic machine learning algorithm based on the Bayes Theorem, used in a wide variety of classification tasks.    1.4.2 What is Con"}</script><link rel="canonical" href="http://example.com/2023/04/30/MachineLearning04/"><link rel="icon" href="/img/avatar.jpg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="jasmine"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="jasmine"></script><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Tianhao&#039;Site</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-04-29T23:00:00.000Z" title="30/04/2023, 00:00:00">2023-04-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-learning/">Machine learning</a></span><span class="level-item">11 minutes read (About 1592 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Machine Learning - ClassificationII</h1><div class="content"><h3 id="1-4-Navie-Bayes"><a href="#1-4-Navie-Bayes" class="headerlink" title="1.4 Navie Bayes"></a>1.4 Navie Bayes</h3><h4 id="1-4-1-What-is-a-Navie-Bayesian"><a href="#1-4-1-What-is-a-Navie-Bayesian" class="headerlink" title="1.4.1 What is a Navie Bayesian?"></a>1.4.1 What is a Navie Bayesian?</h4><p>Naive Bayes is a probabilistic machine learning algorithm based on the Bayes Theorem, used in a wide variety of classification tasks.   </p>
<h4 id="1-4-2-What-is-Conditional-Probability"><a href="#1-4-2-What-is-Conditional-Probability" class="headerlink" title="1.4.2 What is Conditional Probability?"></a>1.4.2 What is Conditional Probability?</h4><p> <strong>Coin Toss and Fair Dice Example</strong> When you flip a fair coin, there is an equal chance of getting either heads or tails. So you can say the probability of getting heads is 50%. Similarly what would be the probability of getting a 1 when you roll a dice with 6 faces? Assuming the dice is fair, the probability of 1&#x2F;6 &#x3D; 0.166.</p>
<p><strong>Playing Cards Example</strong> If you pick a card from the deck, can you guess the probability of getting a queen given the card is a spade? Well, I have already set a condition that the card is a spade.</p>
<p>So, the <strong>denominator</strong> (eligible population) is 13 and not 52. And since there is only one queen in spades, the probability it is a queen given the card is a spade is 1&#x2F;13 &#x3D; 0.077</p>
<p>This is a classic example of conditional probability.</p>
<p>So, when you say the conditional probability of A given B, <strong>it denotes the probability of A occurring given that B has already occurred</strong>.</p>
<p>Mathematically, Conditional probability of A given B can be computed as: P(A|B) &#x3D; P(A AND B) &#x2F; P(B)</p>
<h4 id="1-4-3-The-Bayes-Rule"><a href="#1-4-3-The-Bayes-Rule" class="headerlink" title="1.4.3 The Bayes Rule"></a>1.4.3 The Bayes Rule</h4><p>​          <img src="/2023/04/30/MachineLearning04/img02.png">           <img src="/2023/04/30/MachineLearning04/img01.png"><br>​    </p>
<h4 id="1-4-4-The-Naive-Bayes"><a href="#1-4-4-The-Naive-Bayes" class="headerlink" title="1.4.4 The Naive Bayes"></a>1.4.4 The Naive Bayes</h4><p>The Bayes Rule provides the formula for the probability of Y given X.</p>
<p>But, in real-world problems, you typically have multiple X variables.</p>
<p><em>When the features are independent, we can extend the Bayes Rule to what is called Naive Bayes</em>.</p>
<p>It is called ‘<strong>Naive</strong>’ because of the naive assumption that the X’s are <strong>independent</strong> of each other.</p>
<p><img src="/2023/04/30/MachineLearning04/img03.png"></p>
<h4 id="1-4-5-Naive-Bayes-Example-by-Hand"><a href="#1-4-5-Naive-Bayes-Example-by-Hand" class="headerlink" title="1.4.5 Naive Bayes Example by Hand"></a>1.4.5 Naive Bayes Example by Hand</h4><p>Say you have 1000 fruits which could be either ‘banana’, ‘orange’ or ‘other’. These are the 3 possible classes of the Y variable. We have data for the following X variables, all of which are binary (1 or 0).</p>
<ul>
<li>Long</li>
<li>Sweet</li>
<li>Yellow</li>
</ul>
<p>The first few rows of the training dataset look like this:</p>
<p><img src="/2023/04/30/MachineLearning04/img04.png"></p>
<p>For the sake of computing the probabilities, let’s aggregate the training data to form a counts table like this.</p>
<p><img src="/2023/04/30/MachineLearning04/img05.png"></p>
<p>So the objective of the classifier is to predict if a given fruit is a ‘Banana’ or ‘Orange’ or ‘Other’ when only the 3 features (long, sweet and yellow) are known.</p>
<p>Let’s say you are given a fruit that is: Long, Sweet and Yellow, <strong>can you predict what fruit it is?</strong></p>
<p><strong>Step 1: Compute the ‘Prior’ probabilities for each of the class of fruits.</strong> That is, the proportion of each fruit class out of all the fruits from the population.</p>
<p>You can provide the ‘Priors’ from prior information about the population. Otherwise, it can be computed from the training data. For this case, let’s compute from the training data. Out of 1000 records in training data, you have 500 Bananas, 300 Oranges and 200 Others.</p>
<p>So the respective priors are 0.5, 0.3 and 0.2. P(Y&#x3D;Banana) &#x3D; 500 &#x2F; 1000 &#x3D; 0.50 P(Y&#x3D;Orange) &#x3D; 300 &#x2F; 1000 &#x3D; 0.30 P(Y&#x3D;Other) &#x3D; 200 &#x2F; 1000 &#x3D; 0.20</p>
<p><strong>Step 2: Compute the probability of evidence that goes in the denominator.</strong> This is nothing but the product of P of Xs for all X. This is an optional step because the denominator is the same for all the classes and so will not affect the probabilities. P(x1&#x3D;Long) &#x3D; 500 &#x2F; 1000 &#x3D; 0.50 P(x2&#x3D;Sweet) &#x3D; 650 &#x2F; 1000 &#x3D; 0.65 P(x3&#x3D;Yellow) &#x3D; 800 &#x2F; 1000 &#x3D; 0.80</p>
<p><strong>Step 3: Compute the probability of likelihood of evidences that goes in the numerator.</strong> It is the product of conditional probabilities of the 3 features. If you refer back to the formula, it says P(X1 |Y&#x3D;k).</p>
<p>Here X1 is ‘Long’ and k is ‘Banana’.</p>
<p>That means the probability the fruit is ‘Long’ given that it is a Banana. In the above table, you have 500 Bananas. Out of that 400 is long.</p>
<p>So, P(Long | Banana) &#x3D; 400&#x2F;500 &#x3D; 0.8. Here, I have done it for Banana alone.</p>
<p><strong>Probability of Likelihood for Banana</strong> P(x1&#x3D;Long | Y&#x3D;Banana) &#x3D; 400 &#x2F; 500 &#x3D; 0.80 P(x2&#x3D;Sweet | Y&#x3D;Banana) &#x3D; 350 &#x2F; 500 &#x3D; 0.70 P(x3&#x3D;Yellow | Y&#x3D;Banana) &#x3D; 450 &#x2F; 500 &#x3D; 0.90.</p>
<p>So, the overall probability of Likelihood of evidence for Banana &#x3D; 0.8 * 0.7 * 0.9 &#x3D; 0.504</p>
<p><strong>Step 4: Substitute all the 3 equations into the Naive Bayes formula, to get the probability that it is a banana.</strong></p>
<p><img src="/2023/04/30/MachineLearning04/img06.png"></p>
<p>Similarly, you can compute the probabilities for ‘Orange’ and ‘Other fruit’. The denominator is the same for all 3 cases, so it’s optional to compute. Clearly, Banana gets the highest probability, so that will be our predicted class.</p>
<h4 id="1-4-6-What-is-Laplace-Correction"><a href="#1-4-6-What-is-Laplace-Correction" class="headerlink" title="1.4.6  What is Laplace Correction?"></a>1.4.6  What is Laplace Correction?</h4><p>The value of P(Orange | Long, Sweet and Yellow) was <strong>zero</strong> in the above example, because, P(Long | Orange) was zero.</p>
<p>That is, there were no ‘Long’ oranges in the training data.</p>
<p>It makes sense, but when you have a model with many features, the entire probability will become zero because one of the feature’s value was zero. To avoid this, <strong>we increase the count of the variable with zero to a small value (usually 1) in the numerator, so that the overall probability doesn’t become zero</strong>. This approach is called <strong>‘Laplace Correction’</strong>.</p>
<p>Most Naive Bayes model implementations accept this or an equivalent form of correction as a parameter.</p>
<h4 id="1-4-7-Case-Classifying-News"><a href="#1-4-7-Case-Classifying-News" class="headerlink" title="1.4.7 Case: Classifying News"></a>1.4.7 Case: Classifying News</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_20newsgroups</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">nb_news</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 1）Acquisition of data</span></span><br><span class="line">    news = fetch_20newsgroups(subset=<span class="string">&quot;all&quot;</span>)</span><br><span class="line"><span class="comment"># 2）Dataset division</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(news.data, news.target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3）Feature engineering-tfidf</span></span><br><span class="line">transfer = TfidfVectorizer()</span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4）Navie Bayes predictor process</span></span><br><span class="line">estimator = MultinomialNB()</span><br><span class="line">estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5）model evaluation</span></span><br><span class="line"><span class="comment">#Method 1: Direct comparison of true and predicted values</span></span><br><span class="line">y_predict = estimator.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_predict:\n&quot;</span>, y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Direct comparison of true and predicted values:\n&quot;</span>, y_test == y_predict)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2: Calculation of accuracy</span></span><br><span class="line">score = estimator.score(x_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;accuracy：\n&quot;</span>, score)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    nb_news()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="1-5-Decision-Tree"><a href="#1-5-Decision-Tree" class="headerlink" title="1.5 Decision Tree"></a>1.5 Decision Tree</h2><h4 id="1-5-1-What-are-Decision-Tree-Classifiers"><a href="#1-5-1-What-are-Decision-Tree-Classifiers" class="headerlink" title="1.5.1 What are Decision Tree Classifiers?"></a>1.5.1 What are Decision Tree Classifiers?</h4><p>Decision tree classifiers are <strong>supervised machine learning models</strong>. This means that they use prelabelled data in order to train an algorithm that can be used to make a prediction. </p>
<p>Decision tree classifiers work like <strong>flowcharts</strong>. Each <em>node</em> of a decision tree represents a decision point that splits into two leaf nodes. Each of these nodes represents the outcome of the decision and each of the decisions can also turn into decision nodes. Eventually, the different decisions will lead to a final classification.</p>
<p>The diagram below demonstrates how decision trees work to make decisions. The top node is called the <strong>root node</strong>. Each of the decision points are called <strong>decision nodes</strong>. The final decision point is referred to as a <strong>leaf node</strong>.</p>
<p><img src="/2023/04/30/MachineLearning04/img07.png"></p>
<h4 id="1-5-2-How-do-Decision-Tree-Classifiers-Work"><a href="#1-5-2-How-do-Decision-Tree-Classifiers-Work" class="headerlink" title="1.5.2 How do Decision Tree Classifiers Work?"></a>1.5.2 How do Decision Tree Classifiers Work?</h4><p>Decision trees work by splitting data into a series of binary decisions. These decisions allow you to traverse down the tree based on these decisions. You continue moving through the decisions until you end at a leaf node, which will return the predicted classification.</p>
<p>The image below shows a decision tree being used to make a classification decision:</p>
<p><img src="/2023/04/30/MachineLearning04/img08.png"></p>
<p>How does a decision tree algorithm know which decisions to make? </p>
<ul>
<li><p><strong>The definition of entropy:</strong> H is called information entropy in <strong>bits</strong>.</p>
<p><img src="/2023/04/30/MachineLearning04/img09.jpg"></p>
</li>
<li><p><strong>Information gain</strong><br>  The <strong>information gain g(D,A)</strong> of feature A on the training dataset D, is defined as the difference between the information entropy H(D) of the set D and the information conditional entropy H(D|A) of D under the given conditions of feature A</p>
</li>
</ul>
<p><img src="/2023/04/30/MachineLearning04/img10.png"></p>
<h4 id="1-5-3-Example-Bank-Loan"><a href="#1-5-3-Example-Bank-Loan" class="headerlink" title="1.5.3 Example: Bank Loan"></a>1.5.3 Example: Bank Loan</h4><p><img src="/2023/04/30/MachineLearning04/img11.png"></p>
<p><img src="/2023/04/30/MachineLearning04/img12.jpg"></p>
<p>We use A1, A2, A3, and A4 to represent age, having a job, owning a house, and loan status. The final calculation is <strong>g(D,A1) &#x3D; 0.313</strong>, <strong>g(D,A2) &#x3D; 0.324</strong>, <strong>g(D,A3) &#x3D; 0.420</strong>, g(D,A4) &#x3D; 0.363. so we choose <strong>A3</strong> as the first feature for the division. This way we can slowly build up one tree at a time</p>
<h4 id="1-5-4-Titanic-Survival-Prediction"><a href="#1-5-4-Titanic-Survival-Prediction" class="headerlink" title="1.5.4 Titanic Survival Prediction"></a>1.5.4 Titanic Survival Prediction</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier, export_graphviz</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">titanic</span>():</span><br><span class="line"><span class="comment"># 1 Acquisition of data</span></span><br><span class="line">    path = <span class="string">&quot;http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt&quot;</span></span><br><span class="line">    titanic = pd.read_csv(path)</span><br><span class="line">   <span class="comment"># Filtering eigenvalues and target values</span></span><br><span class="line">    x = titanic[[<span class="string">&quot;pclass&quot;</span>, <span class="string">&quot;age&quot;</span>, <span class="string">&quot;sex&quot;</span>]]</span><br><span class="line">    y = titanic[<span class="string">&quot;survived&quot;</span>]</span><br><span class="line">    <span class="comment"># 2、data process</span></span><br><span class="line">    <span class="comment"># 1）handle missed value</span></span><br><span class="line">    x[<span class="string">&quot;age&quot;</span>].fillna(x[<span class="string">&quot;age&quot;</span>].mean(), inplace=<span class="literal">True</span>) <span class="comment">#fill average value</span></span><br><span class="line">    <span class="comment"># 2) Convert to Dictionary</span></span><br><span class="line">    x = x.to_dict(orient=<span class="string">&quot;records&quot;</span>)</span><br><span class="line">    <span class="comment"># 3、dataset division</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">22</span>)</span><br><span class="line">    <span class="comment"># 4、Dictionary Features Extraction</span></span><br><span class="line">    transfer = DictVectorizer()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.transform(x_test)</span><br><span class="line">    <span class="comment"># 3）Decision Tree Predictor</span></span><br><span class="line">    estimator = DecisionTreeClassifier(criterion=<span class="string">&quot;entropy&quot;</span>, max_depth=<span class="number">8</span>)</span><br><span class="line">    estimator.fit(x_train, y_train)</span><br><span class="line"><span class="comment"># 4）model evaluation</span></span><br><span class="line"><span class="comment"># Method 1: Direct comparison of true and predicted values</span></span><br><span class="line">y_predict = estimator.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y_predict:\n&quot;</span>, y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; Direct comparison of true and predicted values:\n&quot;</span>, y_test == y_predict)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2: Calculating accuracy</span></span><br><span class="line">score = estimator.score(x_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;accuracy：\n&quot;</span>, score)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Visualise Decision Tree</span></span><br><span class="line">export_graphviz(estimator, out_file=<span class="string">&quot;titanic_tree.dot&quot;</span>, feature_names=transfer.get_feature_names())</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    titanic()</span><br></pre></td></tr></table></figure>
</div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/machinelearning/">machinelearning</a><a class="link-muted mr-2" rel="tag" href="/tags/Classification/">Classification</a><a class="link-muted mr-2" rel="tag" href="/tags/NaiveBayes/">NaiveBayes</a><a class="link-muted mr-2" rel="tag" href="/tags/DecisionTree/">DecisionTree</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2023/05/15/MachineLearning05/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Machine Learning - RegressionI</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2023/04/15/MachineLearning03/"><span class="level-item">Machine Learning - ClassificationI</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">32</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Machine-learning/"><span class="level-start"><span class="level-item">Machine learning</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Video-Compression/"><span class="level-start"><span class="level-item">Video Compression</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-09-29T23:00:00.000Z">2023-09-30</time></p><p class="title"><a href="/2023/09/30/KD02/">Knowledge DistillationII</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-09-14T23:00:00.000Z">2023-09-15</time></p><p class="title"><a href="/2023/09/15/KD01/">Knowledge DistillationI</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-08-29T23:00:00.000Z">2023-08-30</time></p><p class="title"><a href="/2023/08/30/ModelCompressionPruning/">Model Compression - Pruning</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-08-14T23:00:00.000Z">2023-08-15</time></p><p class="title"><a href="/2023/08/15/Activation/">Activation Function</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-29T23:00:00.000Z">2023-07-30</time></p><p class="title"><a href="/2023/07/30/BasicsofNeuralNetworksII/">Basics of Neural NetworksII</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a></p></div></article></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Array/"><span class="tag">Array</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BackTracking/"><span class="tag">BackTracking</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BinarySearchTree/"><span class="tag">BinarySearchTree</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BinaryTree/"><span class="tag">BinaryTree</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C-C/"><span class="tag">C/C++</span><span class="tag">32</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Classification/"><span class="tag">Classification</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Combination/"><span class="tag">Combination</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CrossValidation/"><span class="tag">CrossValidation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DecisionTree/"><span class="tag">DecisionTree</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DeepLearning/"><span class="tag">DeepLearning</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DoublePointers/"><span class="tag">DoublePointers</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DynamicProgramming/"><span class="tag">DynamicProgramming</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FeatureExtraction/"><span class="tag">FeatureExtraction</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FeaturePreprocessing/"><span class="tag">FeaturePreprocessing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GreedyAlgorithm/"><span class="tag">GreedyAlgorithm</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Iteration/"><span class="tag">Iteration</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Java/"><span class="tag">Java</span><span class="tag">30</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KNN/"><span class="tag">KNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KnowledgeDistillation/"><span class="tag">KnowledgeDistillation</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LinearRegression/"><span class="tag">LinearRegression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LinkedList/"><span class="tag">LinkedList</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linkedlist/"><span class="tag">Linkedlist</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NaiveBayes/"><span class="tag">NaiveBayes</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Optimization/"><span class="tag">Optimization</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pruning/"><span class="tag">Pruning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">20</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Regression/"><span class="tag">Regression</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Resursion/"><span class="tag">Resursion</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RidgeRegression/"><span class="tag">RidgeRegression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/String/"><span class="tag">String</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TraversalOfBinaryTree/"><span class="tag">TraversalOfBinaryTree</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VideoCompression/"><span class="tag">VideoCompression</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/deeplearning/"><span class="tag">deeplearning</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/loop-invariant/"><span class="tag">loop invariant</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machinelearning/"><span class="tag">machinelearning</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/model-compression/"><span class="tag">model compression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/modelcompression/"><span class="tag">modelcompression</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/quantization/"><span class="tag">quantization</span><span class="tag">1</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.jpg" alt="Tianhao"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Tianhao</p><p class="is-size-6 is-block">a MATH and CS student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Bristol, United Kingdom</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">46</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">38</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/jasminepp/jasminepp.github.io" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/jasminepp/jasminepp.github.io"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/09/"><span class="level-start"><span class="level-item">September 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/08/"><span class="level-start"><span class="level-item">August 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/07/"><span class="level-start"><span class="level-item">July 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/06/"><span class="level-start"><span class="level-item">June 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">May 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/04/"><span class="level-start"><span class="level-item">April 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">March 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">February 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">January 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">December 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">November 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">October 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/09/"><span class="level-start"><span class="level-item">September 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">July 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">June 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">March 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/02/"><span class="level-start"><span class="level-item">February 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/01/"><span class="level-start"><span class="level-item">January 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">December 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/11/"><span class="level-start"><span class="level-item">November 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/10/"><span class="level-start"><span class="level-item">October 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Tianhao&#039;Site</a><p class="is-size-7"><span>&copy; 2023 Tianhao Peng</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="jasmine"></script><script src="jasmine"></script><script src="jasmine" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="jasmine" defer></script><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>